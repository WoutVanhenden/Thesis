{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the value of the environment variable BASIC_DCT_BACKEND is not in [\"JAX\",\"SCIPY\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import napari_sparrow as nas\n",
    "from spatialdata import read_zarr\n",
    "import os\n",
    "import scanpy as sc\n",
    "from spatialdata import SpatialData\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from napari_sparrow.table._table import _back_sdata_table_to_zarr\n",
    "from napari_sparrow.table._annotation import _annotate_celltype\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import anndata as ad\n",
    "from random import sample \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atlas_percentages = pd.read_csv(\"/home/wout/Documents/Thesis_lokaal/Mouse_Liver_Resolve_Data/basic_annotation_percentage_atlas.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_umap(sdata,n_PCAs,n_neighbors):\n",
    "    sc.pp.neighbors(sdata.table, n_neighbors=n_neighbors, n_pcs=n_PCAs)\n",
    "    sc.tl.umap(sdata.table)\n",
    "    sdata.table.uns['umap_'+str(n_PCAs)+'_'+str(n_neighbors)] = sdata.table.uns['umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification(sdata,classification_name,umap_name,path_mg,cell_type_annotation=True,plot_umap=True,plot_dot_plot=True,plot_rank_genes_groups=True,plot_image=True):\n",
    "    # Plot the UMAP\n",
    "    if plot_umap:\n",
    "        sdata.table.uns['umap'] = sdata.table.uns[umap_name]\n",
    "        sc.pl.umap(sdata.table,color=[classification_name])\n",
    "    \n",
    "    # Give the cell type proportions\n",
    "    df_prediction = pd.DataFrame(sdata.table.obs[classification_name].value_counts(normalize=True))\n",
    "    df_prediction.sort_index(inplace=True)\n",
    "    df_pred = df_prediction * 100\n",
    "    if cell_type_annotation:\n",
    "        df_atlas = df_atlas_percentages * 100\n",
    "        df_atlas.loc['Unknown'] = 100-df_atlas.sum()\n",
    "        print(df_atlas.round(6).abs())\n",
    "        print(df_pred.round(6).abs())\n",
    "    else:\n",
    "        print(df_pred.round(6).abs())\n",
    "\n",
    "    # Plot expression of the marker genes for each cluster\n",
    "    if plot_dot_plot:\n",
    "        make_dot_plot(sdata,path_mg,classification_dot_plot=classification_name)\n",
    "\n",
    "    # Plot the highly differential genes for each cluster\n",
    "    if plot_rank_genes_groups:\n",
    "        sdata.table.uns['log1p'][\"base\"] = None\n",
    "        sc.tl.rank_genes_groups(sdata.table, groupby=classification_name,key=classification_name+'_rank_genes')\n",
    "        sc.pl.rank_genes_groups(sdata.table, n_genes=8, sharey=False, show=False)\n",
    "    \n",
    "    # Plot the image with the cells\n",
    "    if plot_image:\n",
    "        nas.pl.plot_shapes(sdata,column=classification_name,img_layer='clahe',shapes_layer = \"segmentation_mask_boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dot plot\n",
    "def make_dot_plot(sdata,path_mg,classification_dot_plot):\n",
    "    marker_genes = pd.read_csv(path_mg, sep=',', index_col=0)\n",
    "    cell_types = marker_genes.columns \n",
    "    df_backup = sdata.table.var.copy(deep=True)     \n",
    "    all_genes = sdata.table.var.index.str.capitalize()\n",
    "    for gene in all_genes:\n",
    "        if gene not in marker_genes.index:\n",
    "            marker_genes.loc[gene] = [0]*len(marker_genes.columns)  \n",
    "    marker_genes.sort_index(inplace=True) \n",
    "    sdata.table.var = sdata.table.var.join(marker_genes)\n",
    "    sdata.table.var['sum'] = sdata.table.var.iloc[:,len(sdata.table.var.columns)-len(cell_types):len(sdata.table.var.columns)].sum(axis=1)\n",
    "    positions_labels_dict = {}\n",
    "    for cell_type in cell_types:\n",
    "        positions = np.where(sdata.table.var[cell_type]==1)[0]\n",
    "        for p in positions:\n",
    "            if (p,p) in positions_labels_dict:\n",
    "                positions_labels_dict[(p,p)] = positions_labels_dict[(p,p)] + '_' + cell_type.lower()\n",
    "            else:\n",
    "                positions_labels_dict[(p,p)] = cell_type.lower()\n",
    "    keys = positions_labels_dict.keys()\n",
    "    values = positions_labels_dict.values()    \n",
    "    sc.pl.dotplot(sdata.table,var_names=sdata.table.var_names,groupby=classification_dot_plot,dendrogram=True,var_group_positions=list(keys),var_group_labels=list(values))    \n",
    "    sdata.table.var = df_backup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_genes_bins(\n",
    "    sdata: SpatialData,\n",
    "    path_marker_genes: str,\n",
    "    bins: int = 25,\n",
    "    delimiter=\",\",\n",
    "    row_norm: bool = False,\n",
    "    repl_columns: Optional[Dict[str, str]] = None,\n",
    "    del_celltypes: Optional[List[str]] = None,\n",
    "    input_dict=False,\n",
    ") -> Tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    The function loads marker genes from a CSV file and scores cells for each cell type using those markers\n",
    "    using scanpy's score_genes function.\n",
    "    Marker genes can be provided as a one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column;\n",
    "    or in dictionary format. The function further allows replacements of column names and deletions of specific marker genes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sdata : SpatialData\n",
    "        Data containing spatial information.\n",
    "    path_marker_genes : str\n",
    "        Path to the CSV file containing the marker genes.\n",
    "        CSV file should be a one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column.\n",
    "    bins : int, optional\n",
    "        Number of bins to use for the sc.tl.score_genes function, default is 25.\n",
    "    delimiter : str, optional\n",
    "        Delimiter used in the CSV file, default is ','.\n",
    "    row_norm : bool, optional\n",
    "        Flag to determine if row normalization is applied, default is False.\n",
    "    repl_columns : dict, optional\n",
    "        Dictionary containing cell types to be replaced. The keys are the original cell type names and\n",
    "        the values are their replacements.\n",
    "    del_celltypes : list, optional\n",
    "        List of cell types to be deleted from the list of possible cell type candidates.\n",
    "        Cells are scored for these cell types, but will not be assigned a cell type from this list.\n",
    "    input_dict : bool, optional\n",
    "        If True, the marker gene list from the CSV file is treated as a dictionary with the first column being\n",
    "        the cell type names and the subsequent columns being the marker genes for those cell types. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with cell types as keys and their respective marker genes as values.\n",
    "    pd.DataFrame\n",
    "        Index:\n",
    "            cells: The index corresponds to indivdual cells ID's.\n",
    "        Columns:\n",
    "            celltypes (as provided via the markers file).\n",
    "        Values:\n",
    "            Score obtained using scanpy's score_genes function for each celltype and for each cell.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The cell type 'unknown_celltype' is reserved for cells that could not be assigned a specific cell type.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Load marker genes from csv\n",
    "    if input_dict:\n",
    "        df_markers = pd.read_csv(\n",
    "            path_marker_genes, header=None, index_col=0, delimiter=delimiter\n",
    "        )\n",
    "        df_markers = df_markers.T\n",
    "        genes_dict = df_markers.to_dict(\"list\")\n",
    "        for i in genes_dict:\n",
    "            genes_dict[i] = [x for x in genes_dict[i] if str(x) != \"nan\"]\n",
    "    # Replace column names in marker genes\n",
    "    else:\n",
    "        df_markers = pd.read_csv(path_marker_genes, index_col=0, delimiter=delimiter)\n",
    "        if repl_columns:\n",
    "            for column, replace in repl_columns.items():\n",
    "                df_markers.columns = df_markers.columns.str.replace(column, replace)\n",
    "\n",
    "        # Create genes dict with all marker genes for every celltype\n",
    "        genes_dict = {}\n",
    "        for i in df_markers:\n",
    "            genes = []\n",
    "            for row, value in enumerate(df_markers[i]):\n",
    "                if value > 0:\n",
    "                    genes.append(df_markers.index[row])\n",
    "            genes_dict[i] = genes\n",
    "\n",
    "    assert (\n",
    "        \"unknown_celltype\" not in genes_dict.keys()\n",
    "    ), \"Cell type 'unknown_celltype' is reserved for cells that could not be assigned a specific cell type\"\n",
    "\n",
    "    # Score all cells for all celltypes\n",
    "    for key, value in genes_dict.items():\n",
    "        try:\n",
    "            sc.tl.score_genes(sdata.table, value, score_name=key,n_bins=bins) # W: key = cell type, value = list of markergenes of that cell type\n",
    "        except ValueError:\n",
    "            log.warning(\n",
    "                f\"Markergenes {value} not present in region, celltype {key} not found\"\n",
    "            )\n",
    "\n",
    "    # Delete genes from marker genes and genes dict\n",
    "    if del_celltypes:\n",
    "        for gene in del_celltypes:\n",
    "            if gene in df_markers.columns:\n",
    "                del df_markers[gene]\n",
    "            if gene in genes_dict.keys():\n",
    "                del genes_dict[gene]\n",
    "\n",
    "    sdata, scoresper_cluster = _annotate_celltype( \n",
    "        sdata=sdata,\n",
    "        celltypes=df_markers.columns,\n",
    "        row_norm=row_norm,\n",
    "        celltype_column=\"annotation\",\n",
    "    )\n",
    "\n",
    "    # add 'unknown_celltype' to the list of celltypes if it is detected.\n",
    "    if \"unknown_celltype\" in sdata.table.obs[\"annotation\"].cat.categories:\n",
    "        genes_dict[\"unknown_celltype\"] = []\n",
    "\n",
    "    name_clustering = 'score_genes_' + str(bins)\n",
    "    sdata.table.uns[name_clustering] = scoresper_cluster\n",
    "    sdata.table.obs.rename(columns={'annotation': 'annotation_'+name_clustering}, inplace=True)\n",
    "    sdata.table.obs.rename(columns={'Cleanliness': 'cleanliness_'+name_clustering}, inplace=True)\n",
    "    del genes_dict['unknown_celltype']\n",
    "    sdata.table.obs.drop(genes_dict.keys(), axis=1, inplace=True)\n",
    "    cols = sdata.table.obs.columns.to_list()\n",
    "    cols_new = cols[0:len(cols)-2]\n",
    "    cols_new.append(cols[len(cols)-1])\n",
    "    cols_new.append(cols[len(cols)-2])\n",
    "    sdata.table.obs  = sdata.table.obs .reindex(columns=cols_new)\n",
    "\n",
    "    _back_sdata_table_to_zarr(sdata)\n",
    "\n",
    "    return genes_dict, scoresper_cluster\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_score_genes(sdata,path_mg,norm_expr_var=False,min_score='Quantile',min_score_q=25,scale_score='MinMax',scale_score_q=1,suffix='')->pd.DataFrame: \n",
    "    # annotate each cell\n",
    "    # method based on score_genes of scanpy but no bins and min max normalization of the scores per cell type\n",
    "    # for each cell, a score is calculated for each cell type: \n",
    "    # sum of the expressions of the markers in the cell - sum of the mean expressions of the markers in all cells\n",
    "    # our expression data does not need to be scaled anymore (norm_expr_var = False) because sc.pp.scale is already applied in Sparrow\n",
    "    path_marker_genes = path_mg,\n",
    "    marker_genes = pd.read_csv(path_marker_genes[0], sep=',',index_col=0)\n",
    "    scores_cell_celltype = pd.DataFrame()\n",
    "    cell_types = marker_genes.columns.tolist()\n",
    "    matrix = sdata.table.to_df()\n",
    "    # correct for the variance of the expression of each gene\n",
    "    if norm_expr_var:\n",
    "        matrix = matrix.div(matrix.std(axis=0))\n",
    "    all_mean_expression = matrix.mean(axis=0)\n",
    "    for cell_type in cell_types:\n",
    "        scores_cells = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            score = 0 \n",
    "            for gene in marker_genes[marker_genes[cell_type] > 0].index.tolist():\n",
    "                score = score + (matrix[gene][i] - all_mean_expression[gene])*marker_genes[cell_type][gene]\n",
    "            scores_cells.append(score)\n",
    "        scores_cell_celltype[cell_type] = scores_cells\n",
    "\n",
    "    # min score to obtain for a cell type, otherwise 'unknown' \n",
    "    if min_score == 'Zero':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok > 0] = True\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok != True] = False\n",
    "    if min_score == 'Quantile':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok > scores_cell_celltype_ok.quantile(min_score_q/100)] = True\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok != True] = False\n",
    "    if min_score == 'None':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok.round(6) == scores_cell_celltype_ok.round(6)] = True\n",
    "\n",
    "    # scale scores per cell type to make them more comparable between cell types (because some cell types have more markers etc.) \n",
    "    if scale_score == 'MinMax':\n",
    "        scores_cell_celltype = scores_cell_celltype.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    if scale_score == 'ZeroMax':\n",
    "        scores_cell_celltype = scores_cell_celltype.apply(lambda x: (x) / (np.max(x))) # (~ min max scaling with min = 0)\n",
    "    if scale_score == 'Nmarkers':\n",
    "        Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "        scores_cell_celltype = scores_cell_celltype.div(Nmarkers)\n",
    "    if scale_score == 'Robust':\n",
    "        for cell_type in cell_types:\n",
    "            if np.percentile(scores_cell_celltype[cell_type],scale_score_q) < np.percentile(scores_cell_celltype[cell_type],100-scale_score_q):\n",
    "                scores_cell_celltype[cell_type] = (scores_cell_celltype[cell_type] - np.percentile(scores_cell_celltype[cell_type],scale_score_q))/(np.percentile(scores_cell_celltype[cell_type],100-scale_score_q)-np.percentile(scores_cell_celltype[cell_type],scale_score_q))\n",
    "            else: # MinMax scaling if percentiles are equal \n",
    "                scores_cell_celltype[cell_type] = (scores_cell_celltype[cell_type]-np.min(scores_cell_celltype[cell_type]))/(np.max(scores_cell_celltype[cell_type])-np.min(scores_cell_celltype[cell_type]))\n",
    "    if scale_score == 'Rank':\n",
    "        for cell_type in cell_types:\n",
    "            scores_cell_celltype[cell_type] = scores_cell_celltype[cell_type].rank(pct=True)\n",
    "            \n",
    "    # cell is annotated with the cell type with the highest score (+ this highest score is above min_score)\n",
    "    scores_cell_celltype[scores_cell_celltype_ok == False] = np.nan\n",
    "    sc_cell_cellt = scores_cell_celltype.idxmax(axis=1).to_dict()\n",
    "    unknown_cells = [k for k, v in sc_cell_cellt.items() if pd.isnull(v)]\n",
    "    # change the values of keys in list\n",
    "    for i in unknown_cells:\n",
    "        sc_cell_cellt[i] = 'Unknown'\n",
    "    sc_cell_cellt = {str(k): v for k, v in sc_cell_cellt.items()}\n",
    "    sdata.table.obs[\"annotation_own_score_genes\"+suffix] = sc_cell_cellt.values()\n",
    "    # cleanliness of each annotation is calculated\n",
    "    max_scores = scores_cell_celltype.max(axis=1)\n",
    "    second_scores = scores_cell_celltype.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
    "    cleanliness = (max_scores - second_scores) / ((max_scores + second_scores) / 2)\n",
    "    sc_cell_cleanl = cleanliness.to_dict()\n",
    "    for i in unknown_cells:\n",
    "        sc_cell_cleanl[i] = 0\n",
    "    sc_cell_cleanl = {str(k): v for k, v in sc_cell_cleanl.items()}\n",
    "    sdata.table.obs[\"score_celltype_own_score_genes\"+suffix] = max_scores.values\n",
    "    sdata.table.obs[\"second_score_celltype_own_score_genes\"+suffix] = second_scores.values\n",
    "    sdata.table.obs[\"cleanliness_own_score_genes\"+suffix] = sc_cell_cleanl.values()\n",
    "    return scores_cell_celltype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_umap_and_perform_leiden_annotation(sdata,path_mg,n_PCAs,n_neighbors,cluster_resolution,norm_expr_var=True,min_score='Quantile',min_score_q=25,scale_score='Robust',scale_score_q=1,clean_th=0.5)->pd.DataFrame:\n",
    "\n",
    "    # make umap and do leiden clustering with scanpy functions\n",
    "    make_umap(sdata,n_neighbors=n_neighbors,n_PCAs=n_PCAs)\n",
    "    column_name = 'leiden_'+str(n_PCAs)+'_'+str(n_neighbors)+'_'+str(cluster_resolution)\n",
    "    sc.tl.leiden(sdata.table,resolution=cluster_resolution,key_added=column_name)\n",
    "\n",
    "    # annotate each leiden cluster\n",
    "    # method based on marker genes and similar to 'own_score_genes' but leiden clusters annotated instead of individual cells\n",
    "    # for each leiden cluster, a score is calculated for each cell type: \n",
    "    # sum of the mean expressions of the markers in leiden cluster - sum of mean expression of the markers in all cells\n",
    "    n_clusters = np.unique(sdata.table.obs[column_name]).size\n",
    "    leiden_mean_expression = {}\n",
    "    for i in range(n_clusters):\n",
    "        an_cluster = sdata.table[sdata.table.obs[column_name]==str(i)]\n",
    "        daf = an_cluster.to_df().mean(axis=0)\n",
    "        pd.DataFrame(daf)\n",
    "        leiden_mean_expression[i] = daf\n",
    "    if norm_expr_var:\n",
    "        matrix = sdata.table.to_df()\n",
    "        all_mean_expression = matrix.div(matrix.std(axis=0)).mean(axis=0)\n",
    "        for i in range(n_clusters):\n",
    "            leiden_mean_expression[i] = leiden_mean_expression[i].div(matrix.std(axis=0))\n",
    "    else:\n",
    "        all_mean_expression = sdata.table.to_df().mean(axis=0)\n",
    "    path_marker_genes = path_mg,\n",
    "    marker_genes = pd.read_csv(path_marker_genes[0], sep=',',index_col=0)\n",
    "    scores_leiden_celltype = pd.DataFrame()\n",
    "    cell_types = marker_genes.columns.tolist()\n",
    "    for cell_type in cell_types:\n",
    "        scores_clusters = []\n",
    "        for i in range(n_clusters):\n",
    "            score = 0 \n",
    "            for gene in marker_genes[marker_genes[cell_type] == 1].index.tolist():\n",
    "                score = score + (leiden_mean_expression[i][gene] - all_mean_expression[gene])\n",
    "            scores_clusters.append(score)\n",
    "        scores_leiden_celltype[cell_type] = scores_clusters\n",
    "    \n",
    "    # min score to obtain for a cell type, otherwise 'unknown' \n",
    "    if min_score == 'Zero':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok > 0] = True\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok != True] = False\n",
    "    if min_score == 'Quantile':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok > scores_leiden_celltype_ok.quantile(min_score_q/100)] = True\n",
    "        print(min_score_q/100)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok != True] = False\n",
    "    if min_score == 'None':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok.round(6) == scores_leiden_celltype_ok.round(6)] = True\n",
    "\n",
    "    # scale scores per cell type to make them more comparable between cell types (because some cell types have more markers etc.) \n",
    "    if scale_score == 'MinMax':\n",
    "        scores_leiden_celltype = scores_leiden_celltype.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    if scale_score == 'ZeroMax':\n",
    "        scores_leiden_celltype = scores_leiden_celltype.apply(lambda x: (x) / (np.max(x))) # (~ min max scaling with min = 0)\n",
    "    if scale_score == 'Nmarkers':\n",
    "        Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "        scores_leiden_celltype = scores_leiden_celltype.div(Nmarkers)\n",
    "    if scale_score == 'Robust':\n",
    "        for cell_type in cell_types:\n",
    "            if np.percentile(scores_leiden_celltype[cell_type],scale_score_q) < np.percentile(scores_leiden_celltype[cell_type],100-scale_score_q):\n",
    "                scores_leiden_celltype[cell_type] = (scores_leiden_celltype[cell_type] - np.percentile(scores_leiden_celltype[cell_type],scale_score_q))/(np.percentile(scores_leiden_celltype[cell_type],100-scale_score_q)-np.percentile(scores_leiden_celltype[cell_type],scale_score_q))\n",
    "            else: # MinMax scaling if percentiles are equal \n",
    "                scores_leiden_celltype[cell_type] = (scores_leiden_celltype[cell_type]-np.min(scores_leiden_celltype[cell_type]))/(np.max(scores_leiden_celltype[cell_type])-np.min(scores_leiden_celltype[cell_type]))\n",
    "    if scale_score == 'Rank':\n",
    "        for cell_type in cell_types:\n",
    "            scores_leiden_celltype[cell_type] = scores_leiden_celltype[cell_type].rank(pct=True)\n",
    "\n",
    "    # cluster is annotated with the cell type with the highest score (+ this highest score is above min_score)\n",
    "    scores_leiden_celltype[scores_leiden_celltype_ok == False] = np.nan\n",
    "    sc_leiden_cellt = scores_leiden_celltype.idxmax(axis=1).to_dict()\n",
    "    unknown_clusters = [k for k, v in sc_leiden_cellt.items() if pd.isnull(v)]\n",
    "\n",
    "    max_scores = scores_leiden_celltype.max(axis=1)\n",
    "    second_scores = scores_leiden_celltype.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
    "    cleanl_per_cluster = (max_scores - second_scores) / ((max_scores + second_scores) / 2)\n",
    "    third_scores = scores_leiden_celltype.apply(lambda x: x.nlargest(3).values[-1], axis=1)\n",
    "    cleanl_per_cluster_extra = (max_scores - third_scores) / ((max_scores + third_scores) / 2)\n",
    "    scores_draft = scores_leiden_celltype.copy(deep=True)\n",
    "    for i in range(n_clusters):\n",
    "        if cleanl_per_cluster[i] < clean_th:\n",
    "            scores_draft.loc[i].at[scores_draft.idxmax(axis=1)[i]] = np.nan \n",
    "            sc_leiden_cellt[i] = sc_leiden_cellt[i] + '/' + scores_draft.idxmax(axis=1)[i]\n",
    "            if cleanl_per_cluster_extra[i] < clean_th:\n",
    "                scores_draft.loc[i].at[scores_draft.idxmax(axis=1)[i]] = np.nan \n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '/' + scores_draft.idxmax(axis=1)[i]\n",
    "                sum = abs(max_scores[i] + second_scores[i] + third_scores[i])\n",
    "                if max_scores[i] > 0:\n",
    "                    p1 = round(100*max_scores[i]/sum)\n",
    "                    p2 = round(100*second_scores[i]/sum)\n",
    "                    p3 = round(100*third_scores[i]/sum)\n",
    "                else:\n",
    "                    p1 = round(100*(sum + max_scores[i])/(2*sum))\n",
    "                    p2 = round(100*(sum + second_scores[i])/(2*sum))\n",
    "                    p3 = round(100*(sum + third_scores[i])/(2*sum))\n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '(' + str(p1) + '%/' + str(p2) + '%/' + str(p3) + '%)'\n",
    "            else:\n",
    "                sum = abs(max_scores[i] + second_scores[i])\n",
    "                if max_scores[i] > 0:\n",
    "                    p1 = round(100*max_scores[i]/sum)\n",
    "                    p2 = round(100*second_scores[i]/sum)\n",
    "                else:\n",
    "                    p1 = round(100*(sum + max_scores[i])/sum)\n",
    "                    p2 = round(100*(sum + second_scores[i])/sum)\n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '(' + str(p1) + '%/' + str(p2) + '%)'\n",
    "    # change the values of keys in list\n",
    "    for i in unknown_clusters:\n",
    "        sc_leiden_cellt[i] = 'unknown'\n",
    "    sc_leiden_cellt = {str(k): v for k, v in sc_leiden_cellt.items()}\n",
    "    sdata.table.obs[\"annotation_\"+column_name]=sdata.table.obs[column_name] \n",
    "    sdata.table.obs[\"annotation_\"+column_name].replace(list(sc_leiden_cellt.keys()),list(sc_leiden_cellt.values()), inplace=True)\n",
    "    b = pd.DataFrame.from_dict(sc_leiden_cellt, orient='index')\n",
    "    cell_type_leiden = {}\n",
    "    cell_types = np.unique(b[0])\n",
    "    for cell_type in cell_types:\n",
    "        indices = b.index[b[0] == cell_type].tolist()\n",
    "        cell_type_leiden[cell_type] = indices\n",
    "    sdata.table.uns[\"mapping_cell_type_\"+column_name] = cell_type_leiden\n",
    "    # cleanliness of the annotation based on highest and second highest score\n",
    "    sc_leiden_cleanl = cleanl_per_cluster.to_dict()\n",
    "    for i in unknown_clusters:\n",
    "        sc_leiden_cleanl[i] = 0\n",
    "    sc_leiden_cleanl = {str(k): v for k, v in sc_leiden_cleanl.items()}\n",
    "    sdata.table.obs[\"cleanliness_\"+column_name]=sdata.table.obs[column_name] \n",
    "    sdata.table.obs[\"cleanliness_\"+column_name].replace(list(sc_leiden_cleanl.keys()),list(sc_leiden_cleanl.values()), inplace=True)\n",
    "\n",
    "    return scores_leiden_celltype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model,N_clusters,labels) -> dict:\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    R = dendrogram(linkage_matrix,truncate_mode='lastp',p=N_clusters,no_plot=True)   \n",
    "    \n",
    "    R2 = dendrogram(linkage_matrix,labels=labels,no_plot=True)  \n",
    "    clusters = np.array(list(dict.fromkeys(R2[\"ivl\"])))\n",
    "    clusters = clusters.astype(str)\n",
    "\n",
    "    # create a label dictionary\n",
    "    temp = {R[\"leaves\"][ii]: clusters[ii] + ' ' + R[\"ivl\"][ii] for ii in range(len(R[\"leaves\"]))}\n",
    "    def llf(xx):\n",
    "        return \"{}\".format(temp[xx])\n",
    "\n",
    "    dendrogram(linkage_matrix,leaf_label_func=llf,leaf_rotation=60.,leaf_font_size=10.,truncate_mode='lastp',p=N_clusters)\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_clustering(sdata,matrix_score_genes,N_clusters,suffix_name=''):\n",
    "    kmeans = KMeans(n_clusters = N_clusters, n_init=10) # run 10 times with different centroid seeds\n",
    "    kmeans_annotation = kmeans.fit_predict(matrix_score_genes)\n",
    "    kmeans_annotation = kmeans_annotation.astype(str)\n",
    "    sdata.table.obs[\"KMeans\"+str(N_clusters)+suffix_name] = kmeans_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hierarchical_clustering(sdata,matrix_score_genes,N_clusters,suffix_name='',levels_dendrogram=4)-> dict:\n",
    "    hier = AgglomerativeClustering(n_clusters=N_clusters,compute_distances=True)\n",
    "    hierarchical = hier.fit(matrix_score_genes)\n",
    "    hierarchical_annotation = hierarchical.fit_predict(matrix_score_genes)\n",
    "    hierarchical_annotation = hierarchical_annotation.astype(str)\n",
    "    sdata.table.obs[\"Hierarchical\"+str(N_clusters)+suffix_name] = hierarchical_annotation\n",
    "    R = plot_dendrogram(hierarchical,N_clusters=N_clusters,labels=hierarchical_annotation)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_expression_marker_genes_of_2_cell_types(anndata,path_mg,type1,type2):\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    gene_set1 = df_mg.index[df_mg[type1]==1].tolist()\n",
    "    gene_set2 = df_mg.index[df_mg[type2]==1].tolist()\n",
    "    df_genes = pd.DataFrame()\n",
    "    overlap = [g for g in gene_set1 if g in gene_set2]\n",
    "    gene_set1 = [g for g in gene_set1 if g not in overlap]\n",
    "    gene_set2 = [g for g in gene_set2 if g not in overlap]\n",
    "    for g in gene_set1:\n",
    "        df_genes[g+' '+type1] = anndata.to_df()[g]\n",
    "    for g in overlap:\n",
    "        df_genes[g+' both'] = anndata.to_df()[g]\n",
    "    for g in gene_set2:\n",
    "        df_genes[g+' '+type2] = anndata.to_df()[g]\n",
    "    sns.heatmap(df_genes.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEGs_between_2_sets_leiden_clusters_compared_to_markers(adata,name_cell_type1, putative_leiden_clusters_cell_type1, name_cell_type2, putative_leiden_clusters_cell_type2, path_mg)->dict:\n",
    "    leidcl1 = [str(x) for x in putative_leiden_clusters_cell_type1]\n",
    "    leidcl2 = [str(x) for x in putative_leiden_clusters_cell_type2]\n",
    "    a = adata.obs['leiden']\n",
    "    for n in leidcl1:\n",
    "        a = a.replace(n,leidcl1[0])\n",
    "    for n in leidcl2:\n",
    "        a = a.replace(n,leidcl2[0])\n",
    "    adata.obs['leiden_mod'] = a\n",
    "    #adata.uns['log1p'][\"base\"] = None\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', groups = [leidcl1[0],leidcl2[0]], method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes=99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    genes.rename(columns = {leidcl1[0]:'gene_'+name_cell_type1,leidcl2[0]:'gene_'+name_cell_type2},inplace=True)\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    pvals_adj.rename(columns = {leidcl1[0]:'pval_adj_'+name_cell_type1,leidcl2[0]:'pval_adj_'+name_cell_type2},inplace=True)\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    logf2.rename(columns = {leidcl1[0]:'logf2_'+name_cell_type1,leidcl2[0]:'logf2_'+name_cell_type2},inplace=True)\n",
    "    df = pd.concat([genes,pvals_adj,logf2],axis=1)\n",
    "    df_ct1_vs_rest = df[['gene_'+name_cell_type1,'pval_adj_'+name_cell_type1,'logf2_'+name_cell_type1]]\n",
    "    df_ct1_vs_rest = df_ct1_vs_rest[(df_ct1_vs_rest['pval_adj_'+name_cell_type1] < 0.01) & (df_ct1_vs_rest['logf2_'+name_cell_type1] > 0)]\n",
    "    df_ct2_vs_rest = df[['gene_'+name_cell_type2,'pval_adj_'+name_cell_type2,'logf2_'+name_cell_type2]]\n",
    "    df_ct2_vs_rest = df_ct2_vs_rest[(df_ct2_vs_rest['pval_adj_'+name_cell_type2] < 0.01) & (df_ct2_vs_rest['logf2_'+name_cell_type2] > 0)]\n",
    "\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', groups = [leidcl1[0]], reference = leidcl2[0], method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes = 99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    genes.rename(columns = {leidcl1[0]:'gene'},inplace=True)\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    pvals_adj.rename(columns = {leidcl1[0]:'pval_adj'},inplace=True)\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    logf2.rename(columns = {leidcl1[0]:'logf2'},inplace=True)\n",
    "    df_ct1_vs_ct2 = pd.concat([genes,pvals_adj,logf2],axis=1)\n",
    "    df_ct1_vs_ct2 = df_ct1_vs_ct2[df_ct1_vs_ct2['pval_adj'] < 0.01]\n",
    "    \n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    mg_ct1 = df_mg.index[df_mg[name_cell_type1]==1].tolist()\n",
    "    mg_ct2 = df_mg.index[df_mg[name_cell_type2]==1].tolist()\n",
    "    mg_overlap = [x for x in mg_ct1 if x in mg_ct2]\n",
    "    df_overlap = df_ct1_vs_ct2[df_ct1_vs_ct2['gene'].isin(mg_overlap)]\n",
    "    candidates_ct1 = df_overlap[df_overlap['logf2']>0]['gene'].to_list()\n",
    "    candidates_ct2 = df_overlap[df_overlap['logf2']<0]['gene'].to_list()\n",
    "    drop_ct2 = []\n",
    "    if len(candidates_ct1)>0:\n",
    "        reject1 = df_ct2_vs_rest[df_ct2_vs_rest['gene_'+name_cell_type2].isin(candidates_ct1)]['gene_'+name_cell_type2].to_list()\n",
    "        drop_ct2 = [x for x in candidates_ct1 if x not in reject1]\n",
    "    drop_ct1 = []\n",
    "    if len(candidates_ct2)>0:\n",
    "        reject2 = df_ct1_vs_rest[df_ct1_vs_rest['gene_'+name_cell_type1].isin(candidates_ct2)]['gene_'+name_cell_type1].to_list()\n",
    "        drop_ct1 = [x for x in candidates_ct2 if x not in reject2]\n",
    "    results = {'DEGs': df_ct1_vs_ct2, 'DEGs_'+name_cell_type1+'_vs_rest': df_ct1_vs_rest, 'DEGs_'+name_cell_type2+'_vs_rest': df_ct2_vs_rest, 'markers_'+name_cell_type1: mg_ct1, 'markers_'+name_cell_type2: mg_ct2, 'overlap_markers': mg_overlap, 'drop_'+name_cell_type1: drop_ct1, 'drop_'+name_cell_type2: drop_ct2}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEGs_between_each_leiden_cluster_and_rest_compared_to_markers(adata,name_cell_types, putative_leiden_clusters_per_cell_type, path_mg)->dict:\n",
    "    a = adata.obs['leiden']\n",
    "    leidcl = []\n",
    "    for putative_leiden_clusters in putative_leiden_clusters_per_cell_type:\n",
    "        L = [str(x) for x in putative_leiden_clusters]\n",
    "        for n in L:\n",
    "            a = a.replace(n,L[0])\n",
    "        leidcl.append(L[0])\n",
    "    adata.obs['leiden_mod'] = a\n",
    "    #adata.uns['log1p'][\"base\"] = None\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes=99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    dict_df_ct_vs_rest = {}\n",
    "    dict_ct_markers = {}\n",
    "    dict_ct_pos_DEG_but_not_marker = {}\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    i = 0\n",
    "    for nr in leidcl:\n",
    "        df_ct_vs_rest = pd.concat([genes[[nr]],pvals_adj[[nr]],logf2[[nr]]],axis=1)\n",
    "        # change column names of df_ct_vs_rest\n",
    "        df_ct_vs_rest.columns = ['gene','pvals_adj','logf2']\n",
    "        df_ct_vs_rest = df_ct_vs_rest[df_ct_vs_rest['pvals_adj'] < 0.01]\n",
    "        dict_df_ct_vs_rest[name_cell_types[i]] = df_ct_vs_rest\n",
    "        markers_ct = df_mg.index[df_mg[name_cell_types[i]]==1].tolist()\n",
    "        dict_ct_markers[name_cell_types[i]] = markers_ct\n",
    "        pos_DEGs_but_no_mg = df_ct_vs_rest[(~df_ct_vs_rest['gene'].isin(markers_ct)) & (df_ct_vs_rest['logf2'] > 0)]\n",
    "        dict_ct_pos_DEG_but_not_marker[name_cell_types[i]] = pos_DEGs_but_no_mg\n",
    "        i = i + 1\n",
    "   \n",
    "    results = {'DEGs': dict_df_ct_vs_rest, 'markers': dict_ct_markers, 'pos_DEGs_but_not_marker': dict_ct_pos_DEG_but_not_marker}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(list1,list2):\n",
    "    list1 = np.ceil(list1)\n",
    "    list2 = np.ceil(list2)\n",
    "    # list1 AND list2\n",
    "    list3 = [list1[i] and list2[i] for i in range(len(list1))]\n",
    "    list4 = [list1[i] or list2[i] for i in range(len(list1))]\n",
    "    Jaccard = np.sum(list3)/np.sum(list4)\n",
    "    return np.round(Jaccard,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_similarity_matrix(path_mg):\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    Jaccard_sim = pd.DataFrame(index=df_mg.columns, columns=df_mg.columns)\n",
    "    for i in df_mg.columns:\n",
    "        for j in df_mg.columns:\n",
    "            Jaccard_sim.loc[i,j] = Jaccard(df_mg[i].to_list(),df_mg[j].to_list())\n",
    "    Jaccard_sim = Jaccard_sim.astype(float)\n",
    "    sns.heatmap(Jaccard_sim,annot=True)\n",
    "    print(df_mg.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_1(adata,cell_types,leiden_clusters,path_mg)->dict:\n",
    "    n_ct = len(cell_types)\n",
    "    marker_gene_drop = {}\n",
    "    for i in range(n_ct):\n",
    "        for j in range(i+1,n_ct):\n",
    "            d = DEGs_between_2_sets_leiden_clusters_compared_to_markers(adata,cell_types[i],leiden_clusters[i],cell_types[j],leiden_clusters[j],path_mg)\n",
    "            if len(d['drop_'+cell_types[i]])>0:\n",
    "                if cell_types[i] in marker_gene_drop:\n",
    "                    for g in d['drop_'+cell_types[i]]:\n",
    "                        if g not in marker_gene_drop[cell_types[i]]:\n",
    "                            marker_gene_drop[cell_types[i]].append(g)\n",
    "                else:\n",
    "                    marker_gene_drop[cell_types[i]] = d['drop_'+cell_types[i]]\n",
    "            if len(d['drop_'+cell_types[j]])>0:\n",
    "                if cell_types[j] in marker_gene_drop:\n",
    "                    for g in d['drop_'+cell_types[j]]:\n",
    "                        if g not in marker_gene_drop[cell_types[j]]:\n",
    "                            marker_gene_drop[cell_types[j]].append(g)\n",
    "                else:\n",
    "                    marker_gene_drop[cell_types[j]] = d['drop_'+cell_types[j]]\n",
    "    print('Summary:')\n",
    "    for key in marker_gene_drop.keys():\n",
    "        print(key)\n",
    "        print('Maybe drop:'+str(marker_gene_drop[key]))\n",
    "    return marker_gene_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_2(adata,cell_types,leiden_clusters,path_mg)->dict:\n",
    "    dict_DEGs = DEGs_between_each_leiden_cluster_and_rest_compared_to_markers(adata,cell_types,leiden_clusters,path_mg)\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    genes = adata.var_names\n",
    "    marker_genes = df_mg.index.tolist()\n",
    "    cell_types = ['Hepa','Kupf','LSEC','Endo vein','Fibr','Stel','Meso','Chol','B cell']\n",
    "    marker_gene_add = {}\n",
    "    for gene in genes:\n",
    "        candidates = []\n",
    "        for i in cell_types:\n",
    "            if gene in dict_DEGs['pos_DEGs_but_not_marker'][i]['gene'].tolist():\n",
    "                candidates.append(i)\n",
    "                if i in marker_gene_add:\n",
    "                    marker_gene_add[i].append(gene)\n",
    "                else:\n",
    "                    marker_gene_add[i] = [gene]\n",
    "        if(len(candidates) > 0):\n",
    "            print(gene)\n",
    "            if gene in marker_genes:\n",
    "                a = df_mg.loc[gene,:]\n",
    "                b = a[a==1].index.values\n",
    "                print('Is marker gene of: '+str(b.tolist()))\n",
    "                print('Could also be a marker gene of: '+str(candidates))\n",
    "            else:\n",
    "                print('Is marker gene of: []')\n",
    "                print('Could also be a marker gene of: '+str(candidates))\n",
    "    print('Summary:')\n",
    "    for key in marker_gene_add.keys():\n",
    "        print(key)\n",
    "        print('Maybe add:'+str(marker_gene_add[key]))\n",
    "    return marker_gene_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_multiple_times(adata,cell_types,leiden_clusters,path_mg,N,n_cells,strategy):\n",
    "    results_runs = {}\n",
    "    for k in range(N):\n",
    "        list_sub_anndata = []\n",
    "        for i in range(len(cell_types)):\n",
    "            leiden_cl = [str(x) for x in leiden_clusters[i]]\n",
    "            leiden = adata[adata.obs['leiden'].isin(leiden_cl),:]\n",
    "            leiden_cells = leiden.obs.index.to_list()\n",
    "            leiden_cells_random = sample(leiden_cells,n_cells)\n",
    "            leiden = leiden[leiden_cells_random,:]\n",
    "            list_sub_anndata.append(leiden)\n",
    "        sub_anndata = ad.concat(list_sub_anndata)\n",
    "        if strategy == 1:\n",
    "            results_runs[k] = Apply_strategy_1(sub_anndata,cell_types,leiden_clusters,path_mg)\n",
    "        if strategy == 2:\n",
    "            results_runs[k] = Apply_strategy_2(sub_anndata,cell_types,leiden_clusters,path_mg)\n",
    "\n",
    "    counts_run = {}\n",
    "    for key in results_runs.keys():\n",
    "        for k in results_runs[key].keys():\n",
    "            if k not in counts_run.keys():\n",
    "                counts_run[k] = results_runs[key][k]\n",
    "            else:\n",
    "                for i in results_runs[key][k]:\n",
    "                    counts_run[k].append(i)\n",
    "    final = {}\n",
    "    for key in counts_run:\n",
    "        df = pd.DataFrame(counts_run[key]).value_counts()\n",
    "        # keep rows with value > N/2\n",
    "        print(df)\n",
    "        df = df[df > N/2]\n",
    "        final[key] = df.index.to_list()\n",
    "\n",
    "    for key in final.keys():\n",
    "        final[key] = [i[0] for i in final[key]]\n",
    "\n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
