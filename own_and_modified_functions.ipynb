{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the value of the environment variable BASIC_DCT_BACKEND is not in [\"JAX\",\"SCIPY\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import napari_sparrow as nas\n",
    "from spatialdata import read_zarr\n",
    "import os\n",
    "import scanpy as sc\n",
    "from spatialdata import SpatialData\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from napari_sparrow.table._table import _back_sdata_table_to_zarr\n",
    "from napari_sparrow.table._annotation import _annotate_celltype\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import anndata as ad\n",
    "from random import sample \n",
    "import seaborn as sns\n",
    "import matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atlas_percentages = pd.read_csv(\"/home/wout/Documents/Thesis_lokaal/Mouse_Liver_Resolve_Data/basic_annotation_percentage_atlas.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_umap(sdata,n_PCAs,n_neighbors):\n",
    "    sc.pp.neighbors(sdata.table, n_neighbors=n_neighbors, n_pcs=n_PCAs)\n",
    "    sc.tl.umap(sdata.table)\n",
    "    sdata.table.uns['umap_'+str(n_PCAs)+'_'+str(n_neighbors)] = sdata.table.uns['umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification(sdata,classification_name,umap_name,path_mg,cell_type_annotation=True,plot_umap=True,plot_dot_plot=True,plot_rank_genes_groups=True,plot_image=True):\n",
    "    # Plot the UMAP\n",
    "    if plot_umap:\n",
    "        sdata.table.uns['umap'] = sdata.table.uns[umap_name]\n",
    "        sc.pl.umap(sdata.table,color=[classification_name])\n",
    "    \n",
    "    # Give the cell type proportions\n",
    "    df_prediction = pd.DataFrame(sdata.table.obs[classification_name].value_counts(normalize=True))\n",
    "    df_prediction.sort_index(inplace=True)\n",
    "    df_pred = df_prediction * 100\n",
    "    if cell_type_annotation:\n",
    "        df_atlas = df_atlas_percentages * 100\n",
    "        df_atlas.loc['Unknown'] = 100-df_atlas.sum()\n",
    "        print(df_atlas.round(6).abs())\n",
    "        print(df_pred.round(6).abs())\n",
    "    else:\n",
    "        print(df_pred.round(6).abs())\n",
    "\n",
    "    # Plot expression of the marker genes for each cluster\n",
    "    if plot_dot_plot:\n",
    "        make_dot_plot(sdata,path_mg,classification_dot_plot=classification_name)\n",
    "\n",
    "    # Plot the highly differential genes for each cluster\n",
    "    if plot_rank_genes_groups:\n",
    "        sdata.table.uns['log1p'][\"base\"] = None\n",
    "        sc.tl.rank_genes_groups(sdata.table, groupby=classification_name,key=classification_name+'_rank_genes')\n",
    "        sc.pl.rank_genes_groups(sdata.table, n_genes=8, sharey=False, show=False)\n",
    "    \n",
    "    # Plot the image with the cells\n",
    "    if plot_image:\n",
    "        nas.pl.plot_shapes(sdata,column=classification_name,img_layer='clahe',shapes_layer = \"segmentation_mask_boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dot plot\n",
    "def make_dot_plot(sdata,path_mg,classification_dot_plot):\n",
    "    marker_genes = pd.read_csv(path_mg, sep=',', index_col=0)\n",
    "    cell_types = marker_genes.columns \n",
    "    df_backup = sdata.table.var.copy(deep=True)     \n",
    "    all_genes = sdata.table.var.index.str.capitalize()\n",
    "    for gene in all_genes:\n",
    "        if gene not in marker_genes.index:\n",
    "            marker_genes.loc[gene] = [0]*len(marker_genes.columns)  \n",
    "    marker_genes.sort_index(inplace=True) \n",
    "    sdata.table.var = sdata.table.var.join(marker_genes)\n",
    "    sdata.table.var['sum'] = sdata.table.var.iloc[:,len(sdata.table.var.columns)-len(cell_types):len(sdata.table.var.columns)].sum(axis=1)\n",
    "    positions_labels_dict = {}\n",
    "    for cell_type in cell_types:\n",
    "        positions = np.where(sdata.table.var[cell_type]>0)[0]\n",
    "        for p in positions:\n",
    "            if (p,p) in positions_labels_dict:\n",
    "                positions_labels_dict[(p,p)] = positions_labels_dict[(p,p)] + '_' + cell_type.lower()\n",
    "            else:\n",
    "                positions_labels_dict[(p,p)] = cell_type.lower()\n",
    "    keys = positions_labels_dict.keys()\n",
    "    values = positions_labels_dict.values()    \n",
    "    sc.pl.dotplot(sdata.table,var_names=sdata.table.var_names,groupby=classification_dot_plot,dendrogram=True,var_group_positions=list(keys),var_group_labels=list(values))    \n",
    "    sdata.table.var = df_backup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_genes_bins(\n",
    "    sdata: SpatialData,\n",
    "    path_marker_genes: str,\n",
    "    bins: int = 25,\n",
    "    delimiter=\",\",\n",
    "    row_norm: bool = False,\n",
    "    repl_columns: Optional[Dict[str, str]] = None,\n",
    "    del_celltypes: Optional[List[str]] = None,\n",
    "    input_dict=False,\n",
    ") -> Tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    The function loads marker genes from a CSV file and scores cells for each cell type using those markers\n",
    "    using scanpy's score_genes function.\n",
    "    Marker genes can be provided as a one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column;\n",
    "    or in dictionary format. The function further allows replacements of column names and deletions of specific marker genes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sdata : SpatialData\n",
    "        Data containing spatial information.\n",
    "    path_marker_genes : str\n",
    "        Path to the CSV file containing the marker genes.\n",
    "        CSV file should be a one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column.\n",
    "    bins : int, optional\n",
    "        Number of bins to use for the sc.tl.score_genes function, default is 25.\n",
    "    delimiter : str, optional\n",
    "        Delimiter used in the CSV file, default is ','.\n",
    "    row_norm : bool, optional\n",
    "        Flag to determine if row normalization is applied, default is False.\n",
    "    repl_columns : dict, optional\n",
    "        Dictionary containing cell types to be replaced. The keys are the original cell type names and\n",
    "        the values are their replacements.\n",
    "    del_celltypes : list, optional\n",
    "        List of cell types to be deleted from the list of possible cell type candidates.\n",
    "        Cells are scored for these cell types, but will not be assigned a cell type from this list.\n",
    "    input_dict : bool, optional\n",
    "        If True, the marker gene list from the CSV file is treated as a dictionary with the first column being\n",
    "        the cell type names and the subsequent columns being the marker genes for those cell types. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with cell types as keys and their respective marker genes as values.\n",
    "    pd.DataFrame\n",
    "        Index:\n",
    "            cells: The index corresponds to indivdual cells ID's.\n",
    "        Columns:\n",
    "            celltypes (as provided via the markers file).\n",
    "        Values:\n",
    "            Score obtained using scanpy's score_genes function for each celltype and for each cell.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The cell type 'unknown_celltype' is reserved for cells that could not be assigned a specific cell type.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Load marker genes from csv\n",
    "    if input_dict:\n",
    "        df_markers = pd.read_csv(\n",
    "            path_marker_genes, header=None, index_col=0, delimiter=delimiter\n",
    "        )\n",
    "        df_markers = df_markers.T\n",
    "        genes_dict = df_markers.to_dict(\"list\")\n",
    "        for i in genes_dict:\n",
    "            genes_dict[i] = [x for x in genes_dict[i] if str(x) != \"nan\"]\n",
    "    # Replace column names in marker genes\n",
    "    else:\n",
    "        df_markers = pd.read_csv(path_marker_genes, index_col=0, delimiter=delimiter)\n",
    "        if repl_columns:\n",
    "            for column, replace in repl_columns.items():\n",
    "                df_markers.columns = df_markers.columns.str.replace(column, replace)\n",
    "\n",
    "        # Create genes dict with all marker genes for every celltype\n",
    "        genes_dict = {}\n",
    "        for i in df_markers:\n",
    "            genes = []\n",
    "            for row, value in enumerate(df_markers[i]):\n",
    "                if value > 0:\n",
    "                    genes.append(df_markers.index[row])\n",
    "            genes_dict[i] = genes\n",
    "\n",
    "    assert (\n",
    "        \"unknown_celltype\" not in genes_dict.keys()\n",
    "    ), \"Cell type 'unknown_celltype' is reserved for cells that could not be assigned a specific cell type\"\n",
    "\n",
    "    # Score all cells for all celltypes\n",
    "    for key, value in genes_dict.items():\n",
    "        try:\n",
    "            sc.tl.score_genes(sdata.table, value, score_name=key,n_bins=bins) # W: key = cell type, value = list of markergenes of that cell type\n",
    "        except ValueError:\n",
    "            log.warning(\n",
    "                f\"Markergenes {value} not present in region, celltype {key} not found\"\n",
    "            )\n",
    "\n",
    "    # Delete genes from marker genes and genes dict\n",
    "    if del_celltypes:\n",
    "        for gene in del_celltypes:\n",
    "            if gene in df_markers.columns:\n",
    "                del df_markers[gene]\n",
    "            if gene in genes_dict.keys():\n",
    "                del genes_dict[gene]\n",
    "\n",
    "    sdata, scoresper_cluster = _annotate_celltype( \n",
    "        sdata=sdata,\n",
    "        celltypes=df_markers.columns,\n",
    "        row_norm=row_norm,\n",
    "        celltype_column=\"annotation\",\n",
    "    )\n",
    "\n",
    "    # add 'unknown_celltype' to the list of celltypes if it is detected.\n",
    "    if \"unknown_celltype\" in sdata.table.obs[\"annotation\"].cat.categories:\n",
    "        genes_dict[\"unknown_celltype\"] = []\n",
    "\n",
    "    name_clustering = 'score_genes_' + str(bins)\n",
    "    sdata.table.uns[name_clustering] = scoresper_cluster\n",
    "    sdata.table.obs.rename(columns={'annotation': 'annotation_'+name_clustering}, inplace=True)\n",
    "    sdata.table.obs.rename(columns={'Cleanliness': 'cleanliness_'+name_clustering}, inplace=True)\n",
    "    # check if 'unknown_celltype' is a column of genes_dict\n",
    "    if 'unknown_celltype' in genes_dict:\n",
    "        del genes_dict['unknown_celltype']\n",
    "    sdata.table.obs.drop(genes_dict.keys(), axis=1, inplace=True)\n",
    "    cols = sdata.table.obs.columns.to_list()\n",
    "    cols_new = cols[0:len(cols)-2]\n",
    "    cols_new.append(cols[len(cols)-1])\n",
    "    cols_new.append(cols[len(cols)-2])\n",
    "    sdata.table.obs  = sdata.table.obs .reindex(columns=cols_new)\n",
    "\n",
    "    _back_sdata_table_to_zarr(sdata)\n",
    "\n",
    "    return genes_dict, scoresper_cluster\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_score_genes(anndata,path_mg,norm_expr_var=False,min_score='Quantile',min_score_q=25,scale_score='MinMax',scale_score_q=1,suffix='',mean = 'all',mean_values = None)->pd.DataFrame: \n",
    "    # annotate each cell\n",
    "    # method based on score_genes of scanpy but no bins and min max normalization of the scores per cell type\n",
    "    # for each cell, a score is calculated for each cell type: \n",
    "    # sum of the expressions of the markers in the cell - sum of the mean expressions of the markers in all cells\n",
    "    # our expression data does not need to be scaled anymore (norm_expr_var = False) because sc.pp.scale is already applied in Sparrow\n",
    "    path_marker_genes = path_mg,\n",
    "    marker_genes = pd.read_csv(path_marker_genes[0], sep=',',index_col=0)\n",
    "    scores_cell_celltype = pd.DataFrame()\n",
    "    cell_types = marker_genes.columns.tolist()\n",
    "    matrix = anndata.to_df()\n",
    "    # correct for the variance of the expression of each gene\n",
    "    if norm_expr_var:\n",
    "        matrix = matrix.div(matrix.std(axis=0))\n",
    "    if mean == 'all':\n",
    "        mean_expression = matrix.mean(axis=0)\n",
    "    if mean == 'given':\n",
    "        mean_expression = mean_values\n",
    "    \n",
    "    for cell_type in cell_types:\n",
    "        scores_cells = []\n",
    "        for i in range(matrix.shape[0]):\n",
    "            score = 0 \n",
    "            for gene in marker_genes[marker_genes[cell_type] > 0].index.tolist():\n",
    "                score = score + (matrix[gene][i] - mean_expression[gene])*marker_genes[cell_type][gene]\n",
    "            scores_cells.append(score)\n",
    "        scores_cell_celltype[cell_type] = scores_cells\n",
    "\n",
    "    # min score to obtain for a cell type, otherwise 'unknown' \n",
    "    if min_score == 'Zero':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok > 0] = True\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok != True] = False\n",
    "    if min_score == 'Quantile':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok > scores_cell_celltype_ok.quantile(min_score_q/100)] = True\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok != True] = False\n",
    "    if min_score == 'None':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok.round(6) == scores_cell_celltype_ok.round(6)] = True\n",
    "\n",
    "    # scale scores per cell type to make them more comparable between cell types (because some cell types have more markers etc.) \n",
    "    if scale_score == 'MinMax':\n",
    "        # if you chose this the '- mean_expression' you did before does not have an effect\n",
    "        scores_cell_celltype = scores_cell_celltype.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    if scale_score == 'ZeroMax':\n",
    "        scores_cell_celltype = scores_cell_celltype.apply(lambda x: (x) / (np.max(x))) # (~ min max scaling with min = 0)\n",
    "    if scale_score == 'Nmarkers':\n",
    "        Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "        scores_cell_celltype = scores_cell_celltype.div(Nmarkers)\n",
    "    if scale_score == 'Robust':\n",
    "        for cell_type in cell_types:\n",
    "            if np.percentile(scores_cell_celltype[cell_type],scale_score_q) < np.percentile(scores_cell_celltype[cell_type],100-scale_score_q):\n",
    "                scores_cell_celltype[cell_type] = (scores_cell_celltype[cell_type] - np.percentile(scores_cell_celltype[cell_type],scale_score_q))/(np.percentile(scores_cell_celltype[cell_type],100-scale_score_q)-np.percentile(scores_cell_celltype[cell_type],scale_score_q))\n",
    "            else: # MinMax scaling if percentiles are equal \n",
    "                scores_cell_celltype[cell_type] = (scores_cell_celltype[cell_type]-np.min(scores_cell_celltype[cell_type]))/(np.max(scores_cell_celltype[cell_type])-np.min(scores_cell_celltype[cell_type]))\n",
    "    if scale_score == 'Rank':\n",
    "        for cell_type in cell_types:\n",
    "            scores_cell_celltype[cell_type] = scores_cell_celltype[cell_type].rank(pct=True)\n",
    "            \n",
    "    \n",
    "\n",
    "    # cell is annotated with the cell type with the highest score (+ this highest score is above min_score)\n",
    "    scores_cell_celltype[scores_cell_celltype_ok == False] = np.nan\n",
    "    sc_cell_cellt = scores_cell_celltype.idxmax(axis=1).to_dict()\n",
    "    unknown_cells = [k for k, v in sc_cell_cellt.items() if pd.isnull(v)]\n",
    "    # change the values of keys in list\n",
    "    for i in unknown_cells:\n",
    "        sc_cell_cellt[i] = 'Unknown'\n",
    "    sc_cell_cellt = {str(k): v for k, v in sc_cell_cellt.items()}\n",
    "    anndata.obs[\"annotation_own_score_genes\"+suffix] = sc_cell_cellt.values()\n",
    "    # cleanliness of each annotation is calculated\n",
    "    max_scores = scores_cell_celltype.max(axis=1)\n",
    "    second_scores = scores_cell_celltype.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
    "    cleanliness = (max_scores - second_scores) / ((max_scores + second_scores) / 2)\n",
    "    sc_cell_cleanl = cleanliness.to_dict()\n",
    "    for i in unknown_cells:\n",
    "        sc_cell_cleanl[i] = 0\n",
    "    sc_cell_cleanl = {str(k): v for k, v in sc_cell_cleanl.items()}\n",
    "    anndata.obs[\"score_celltype_own_score_genes\"+suffix] = max_scores.values\n",
    "    anndata.obs[\"second_score_celltype_own_score_genes\"+suffix] = second_scores.values\n",
    "    anndata.obs[\"cleanliness_own_score_genes\"+suffix] = sc_cell_cleanl.values()\n",
    "    return scores_cell_celltype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_score_genes_iterative(anndata,path_mg,suffix='',nr_iterations=5):\n",
    "    # initial clustering: = typical own_score_genes\n",
    "    # 'mean expression' is over all cells'\n",
    "    # but you do MinMax scaling so 'mean expression' does not have an effect  \n",
    "    scores = own_score_genes(anndata,path_mg,suffix=suffix)\n",
    "    print(anndata.obs['annotation_own_score_genes'+suffix].value_counts()/len(anndata.obs['annotation_own_score_genes'+suffix]))\n",
    "    sc.pl.umap(anndata,color=['annotation_own_score_genes'+suffix])\n",
    "    #print(scores)\n",
    "    # iterative clustering: \n",
    "    # own_score_genes again but now no (MinMax) scaling hence mean_expression has an effect\n",
    "    # mean expression with fair contribution of each cell type (cell types are based on the previous clustering)\n",
    "    changes = []\n",
    "    for iteration in range(nr_iterations):\n",
    "        if pd.DataFrame(anndata.obs[\"annotation_own_score_genes\"+suffix]).value_counts().sort_values(ascending=True).index[0] != 'Unknown':\n",
    "            n_cells = pd.DataFrame(anndata.obs[\"annotation_own_score_genes\"+suffix]).value_counts().sort_values(ascending=True)[0]\n",
    "        else:\n",
    "            n_cells = pd.DataFrame(anndata.obs[\"annotation_own_score_genes\"+suffix]).value_counts().sort_values(ascending=True)[1]\n",
    "        print('number of cells of each cell type to calculate the mean expression in this iteration: '+n_cells)\n",
    "        cell_types = np.unique(anndata.obs[\"annotation_own_score_genes\"+suffix]).tolist()\n",
    "        cell_types.remove('Unknown')\n",
    "        selected_cells = []\n",
    "        for ct in cell_types:\n",
    "            l = pd.DataFrame(anndata.obs[\"annotation_own_score_genes\"+suffix]==ct)\n",
    "            l = l.index[l[\"annotation_own_score_genes\"+suffix]].tolist()\n",
    "            ct_sel = anndata[l,:]\n",
    "            ct_sel_cells = ct_sel.obs.index.to_list()\n",
    "            ct_sel_cells_random = sample(ct_sel_cells,n_cells)\n",
    "            selected_cells.extend(ct_sel_cells_random)\n",
    "        sub_anndata = anndata[selected_cells,:]\n",
    "        next_mean = sub_anndata.to_df().mean(axis=0)\n",
    "\n",
    "        if 'annotation_own_score_genes_previous' in anndata.obs.columns:\n",
    "            anndata.obs.drop(columns=['annotation_own_score_genes_previous'], inplace=True)       \n",
    "        anndata.obs.rename(columns={'annotation_own_score_genes'+suffix: 'annotation_own_score_genes_previous'+suffix}, inplace=True)\n",
    "        scores = own_score_genes(anndata,path_mg,scale_score='No',suffix=suffix,mean='given',mean_values=next_mean)\n",
    "        #print(scores)\n",
    "        t = anndata.obs[\"annotation_own_score_genes\"+suffix] == anndata.obs[\"annotation_own_score_genes_previous\"+suffix]\n",
    "        anndata.obs[\"own_score_genes_diff_iter\"+suffix] = [int(x) for x in t.to_list()]\n",
    "        fr = anndata.obs['own_score_genes_diff_iter'+suffix].value_counts()/len(anndata.obs['own_score_genes_diff_iter'+suffix])\n",
    "        sc.pl.umap(anndata,color=['own_score_genes_diff_iter'+suffix])\n",
    "        print(fr[0])\n",
    "        changes.append(fr[0])\n",
    "        sc.pl.umap(anndata,color=['annotation_own_score_genes'+suffix])\n",
    "        print(anndata.obs['annotation_own_score_genes'+suffix].value_counts()/len(anndata.obs['annotation_own_score_genes'+suffix]))\n",
    "    plt.plot(list(range(1,nr_iterations+1,1)),changes)    \n",
    "    # make x-axis integers and start from 1\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Fraction of cells with changed annotation')\n",
    "    return changes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_umap_and_perform_leiden_annotation(sdata,path_mg,n_PCAs,n_neighbors,cluster_resolution,norm_expr_var=True,min_score='Quantile',min_score_q=25,scale_score='Robust',scale_score_q=1,clean_th=0.5)->pd.DataFrame:\n",
    "\n",
    "    # make umap and do leiden clustering with scanpy functions\n",
    "    make_umap(sdata,n_neighbors=n_neighbors,n_PCAs=n_PCAs)\n",
    "    column_name = 'leiden_'+str(n_PCAs)+'_'+str(n_neighbors)+'_'+str(cluster_resolution)\n",
    "    sc.tl.leiden(sdata.table,resolution=cluster_resolution,key_added=column_name)\n",
    "\n",
    "    # annotate each leiden cluster\n",
    "    # method based on marker genes and similar to 'own_score_genes' but leiden clusters annotated instead of individual cells\n",
    "    # for each leiden cluster, a score is calculated for each cell type: \n",
    "    # sum of the mean expressions of the markers in leiden cluster - sum of mean expression of the markers in all cells\n",
    "    n_clusters = np.unique(sdata.table.obs[column_name]).size\n",
    "    leiden_mean_expression = {}\n",
    "    for i in range(n_clusters):\n",
    "        an_cluster = sdata.table[sdata.table.obs[column_name]==str(i)]\n",
    "        daf = an_cluster.to_df().mean(axis=0)\n",
    "        pd.DataFrame(daf)\n",
    "        leiden_mean_expression[i] = daf\n",
    "    if norm_expr_var:\n",
    "        matrix = sdata.table.to_df()\n",
    "        all_mean_expression = matrix.div(matrix.std(axis=0)).mean(axis=0)\n",
    "        for i in range(n_clusters):\n",
    "            leiden_mean_expression[i] = leiden_mean_expression[i].div(matrix.std(axis=0))\n",
    "    else:\n",
    "        all_mean_expression = sdata.table.to_df().mean(axis=0)\n",
    "    path_marker_genes = path_mg,\n",
    "    marker_genes = pd.read_csv(path_marker_genes[0], sep=',',index_col=0)\n",
    "    scores_leiden_celltype = pd.DataFrame()\n",
    "    cell_types = marker_genes.columns.tolist()\n",
    "    for cell_type in cell_types:\n",
    "        scores_clusters = []\n",
    "        for i in range(n_clusters):\n",
    "            score = 0 \n",
    "            for gene in marker_genes[marker_genes[cell_type] == 1].index.tolist():\n",
    "                score = score + (leiden_mean_expression[i][gene] - all_mean_expression[gene])\n",
    "            scores_clusters.append(score)\n",
    "        scores_leiden_celltype[cell_type] = scores_clusters\n",
    "    \n",
    "    # min score to obtain for a cell type, otherwise 'unknown' \n",
    "    if min_score == 'Zero':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok > 0] = True\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok != True] = False\n",
    "    if min_score == 'Quantile':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok > scores_leiden_celltype_ok.quantile(min_score_q/100)] = True\n",
    "        print(min_score_q/100)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok != True] = False\n",
    "    if min_score == 'None':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok.round(6) == scores_leiden_celltype_ok.round(6)] = True\n",
    "\n",
    "    # scale scores per cell type to make them more comparable between cell types (because some cell types have more markers etc.) \n",
    "    if scale_score == 'MinMax':\n",
    "        scores_leiden_celltype = scores_leiden_celltype.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    if scale_score == 'ZeroMax':\n",
    "        scores_leiden_celltype = scores_leiden_celltype.apply(lambda x: (x) / (np.max(x))) # (~ min max scaling with min = 0)\n",
    "    if scale_score == 'Nmarkers':\n",
    "        Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "        scores_leiden_celltype = scores_leiden_celltype.div(Nmarkers)\n",
    "    if scale_score == 'Robust':\n",
    "        for cell_type in cell_types:\n",
    "            if np.percentile(scores_leiden_celltype[cell_type],scale_score_q) < np.percentile(scores_leiden_celltype[cell_type],100-scale_score_q):\n",
    "                scores_leiden_celltype[cell_type] = (scores_leiden_celltype[cell_type] - np.percentile(scores_leiden_celltype[cell_type],scale_score_q))/(np.percentile(scores_leiden_celltype[cell_type],100-scale_score_q)-np.percentile(scores_leiden_celltype[cell_type],scale_score_q))\n",
    "            else: # MinMax scaling if percentiles are equal \n",
    "                scores_leiden_celltype[cell_type] = (scores_leiden_celltype[cell_type]-np.min(scores_leiden_celltype[cell_type]))/(np.max(scores_leiden_celltype[cell_type])-np.min(scores_leiden_celltype[cell_type]))\n",
    "    if scale_score == 'Rank':\n",
    "        for cell_type in cell_types:\n",
    "            scores_leiden_celltype[cell_type] = scores_leiden_celltype[cell_type].rank(pct=True)\n",
    "\n",
    "    # cluster is annotated with the cell type with the highest score (+ this highest score is above min_score)\n",
    "    scores_leiden_celltype[scores_leiden_celltype_ok == False] = np.nan\n",
    "    sc_leiden_cellt = scores_leiden_celltype.idxmax(axis=1).to_dict()\n",
    "    unknown_clusters = [k for k, v in sc_leiden_cellt.items() if pd.isnull(v)]\n",
    "\n",
    "    max_scores = scores_leiden_celltype.max(axis=1)\n",
    "    second_scores = scores_leiden_celltype.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
    "    cleanl_per_cluster = (max_scores - second_scores) / ((max_scores + second_scores) / 2)\n",
    "    third_scores = scores_leiden_celltype.apply(lambda x: x.nlargest(3).values[-1], axis=1)\n",
    "    cleanl_per_cluster_extra = (max_scores - third_scores) / ((max_scores + third_scores) / 2)\n",
    "    scores_draft = scores_leiden_celltype.copy(deep=True)\n",
    "    for i in range(n_clusters):\n",
    "        if cleanl_per_cluster[i] < clean_th:\n",
    "            scores_draft.loc[i].at[scores_draft.idxmax(axis=1)[i]] = np.nan \n",
    "            sc_leiden_cellt[i] = sc_leiden_cellt[i] + '/' + scores_draft.idxmax(axis=1)[i]\n",
    "            if cleanl_per_cluster_extra[i] < clean_th:\n",
    "                scores_draft.loc[i].at[scores_draft.idxmax(axis=1)[i]] = np.nan \n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '/' + scores_draft.idxmax(axis=1)[i]\n",
    "                sum = abs(max_scores[i] + second_scores[i] + third_scores[i])\n",
    "                if max_scores[i] > 0:\n",
    "                    p1 = round(100*max_scores[i]/sum)\n",
    "                    p2 = round(100*second_scores[i]/sum)\n",
    "                    p3 = round(100*third_scores[i]/sum)\n",
    "                else:\n",
    "                    p1 = round(100*(sum + max_scores[i])/(2*sum))\n",
    "                    p2 = round(100*(sum + second_scores[i])/(2*sum))\n",
    "                    p3 = round(100*(sum + third_scores[i])/(2*sum))\n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '(' + str(p1) + '%/' + str(p2) + '%/' + str(p3) + '%)'\n",
    "            else:\n",
    "                sum = abs(max_scores[i] + second_scores[i])\n",
    "                if max_scores[i] > 0:\n",
    "                    p1 = round(100*max_scores[i]/sum)\n",
    "                    p2 = round(100*second_scores[i]/sum)\n",
    "                else:\n",
    "                    p1 = round(100*(sum + max_scores[i])/sum)\n",
    "                    p2 = round(100*(sum + second_scores[i])/sum)\n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '(' + str(p1) + '%/' + str(p2) + '%)'\n",
    "    # change the values of keys in list\n",
    "    for i in unknown_clusters:\n",
    "        sc_leiden_cellt[i] = 'Unknown'\n",
    "    sc_leiden_cellt = {str(k): v for k, v in sc_leiden_cellt.items()}\n",
    "    sdata.table.obs[\"annotation_\"+column_name]=sdata.table.obs[column_name] \n",
    "    sdata.table.obs[\"annotation_\"+column_name].replace(list(sc_leiden_cellt.keys()),list(sc_leiden_cellt.values()), inplace=True)\n",
    "    b = pd.DataFrame.from_dict(sc_leiden_cellt, orient='index')\n",
    "    cell_type_leiden = {}\n",
    "    cell_types = np.unique(b[0])\n",
    "    for cell_type in cell_types:\n",
    "        indices = b.index[b[0] == cell_type].tolist()\n",
    "        cell_type_leiden[cell_type] = indices\n",
    "    sdata.table.uns[\"mapping_cell_type_\"+column_name] = cell_type_leiden\n",
    "    # cleanliness of the annotation based on highest and second highest score\n",
    "    sc_leiden_cleanl = cleanl_per_cluster.to_dict()\n",
    "    for i in unknown_clusters:\n",
    "        sc_leiden_cleanl[i] = 0\n",
    "    sc_leiden_cleanl = {str(k): v for k, v in sc_leiden_cleanl.items()}\n",
    "    sdata.table.obs[\"cleanliness_\"+column_name]=sdata.table.obs[column_name] \n",
    "    sdata.table.obs[\"cleanliness_\"+column_name].replace(list(sc_leiden_cleanl.keys()),list(sc_leiden_cleanl.values()), inplace=True)\n",
    "\n",
    "    return scores_leiden_celltype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model,N_clusters,labels) -> dict:\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    R = dendrogram(linkage_matrix,truncate_mode='lastp',p=N_clusters,no_plot=True)   \n",
    "    \n",
    "    R2 = dendrogram(linkage_matrix,labels=labels,no_plot=True)  \n",
    "    clusters = np.array(list(dict.fromkeys(R2[\"ivl\"])))\n",
    "    clusters = clusters.astype(str)\n",
    "\n",
    "    # create a label dictionary\n",
    "    temp = {R[\"leaves\"][ii]: clusters[ii] + ' ' + R[\"ivl\"][ii] for ii in range(len(R[\"leaves\"]))}\n",
    "    def llf(xx):\n",
    "        return \"{}\".format(temp[xx])\n",
    "\n",
    "    dendrogram(linkage_matrix,leaf_label_func=llf,leaf_rotation=60.,leaf_font_size=10.,truncate_mode='lastp',p=N_clusters)\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_clustering(sdata,matrix_score_genes,N_clusters,suffix_name=''):\n",
    "    kmeans = KMeans(n_clusters = N_clusters, n_init=10) # run 10 times with different centroid seeds\n",
    "    kmeans_annotation = kmeans.fit_predict(matrix_score_genes)\n",
    "    kmeans_annotation = kmeans_annotation.astype(str)\n",
    "    sdata.table.obs[\"KMeans\"+str(N_clusters)+suffix_name] = kmeans_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hierarchical_clustering(sdata,matrix_score_genes,N_clusters,suffix_name='',levels_dendrogram=4)-> dict:\n",
    "    hier = AgglomerativeClustering(n_clusters=N_clusters,compute_distances=True)\n",
    "    hierarchical = hier.fit(matrix_score_genes)\n",
    "    hierarchical_annotation = hierarchical.fit_predict(matrix_score_genes)\n",
    "    hierarchical_annotation = hierarchical_annotation.astype(str)\n",
    "    sdata.table.obs[\"Hierarchical\"+str(N_clusters)+suffix_name] = hierarchical_annotation\n",
    "    R = plot_dendrogram(hierarchical,N_clusters=N_clusters,labels=hierarchical_annotation)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_expression_marker_genes_of_2_cell_types(anndata,path_mg,type1,type2):\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    gene_set1 = df_mg.index[df_mg[type1]>0].tolist()\n",
    "    gene_set2 = df_mg.index[df_mg[type2]>0].tolist()\n",
    "    df_genes = pd.DataFrame()\n",
    "    overlap = [g for g in gene_set1 if g in gene_set2]\n",
    "    gene_set1 = [g for g in gene_set1 if g not in overlap]\n",
    "    gene_set2 = [g for g in gene_set2 if g not in overlap]\n",
    "    for g in gene_set1:\n",
    "        df_genes[g+' '+type1] = anndata.to_df()[g]\n",
    "    for g in overlap:\n",
    "        df_genes[g+' both'] = anndata.to_df()[g]\n",
    "    for g in gene_set2:\n",
    "        df_genes[g+' '+type2] = anndata.to_df()[g]\n",
    "    sns.heatmap(df_genes.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEGs_between_2_sets_leiden_clusters_compared_to_markers(adata,name_cell_type1, putative_leiden_clusters_cell_type1, name_cell_type2, putative_leiden_clusters_cell_type2, path_mg)->dict:\n",
    "    leidcl1 = [str(x) for x in putative_leiden_clusters_cell_type1]\n",
    "    leidcl2 = [str(x) for x in putative_leiden_clusters_cell_type2]\n",
    "    a = adata.obs['leiden']\n",
    "    for n in leidcl1:\n",
    "        a = a.replace(n,leidcl1[0])\n",
    "    for n in leidcl2:\n",
    "        a = a.replace(n,leidcl2[0])\n",
    "    adata.obs['leiden_mod'] = a\n",
    "    #adata.uns['log1p'][\"base\"] = None\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', groups = [leidcl1[0],leidcl2[0]], method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes=99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    genes.rename(columns = {leidcl1[0]:'gene_'+name_cell_type1,leidcl2[0]:'gene_'+name_cell_type2},inplace=True)\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    pvals_adj.rename(columns = {leidcl1[0]:'pval_adj_'+name_cell_type1,leidcl2[0]:'pval_adj_'+name_cell_type2},inplace=True)\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    logf2.rename(columns = {leidcl1[0]:'logf2_'+name_cell_type1,leidcl2[0]:'logf2_'+name_cell_type2},inplace=True)\n",
    "    df = pd.concat([genes,pvals_adj,logf2],axis=1)\n",
    "    df_ct1_vs_rest = df[['gene_'+name_cell_type1,'pval_adj_'+name_cell_type1,'logf2_'+name_cell_type1]]\n",
    "    df_ct1_vs_rest = df_ct1_vs_rest[(df_ct1_vs_rest['pval_adj_'+name_cell_type1] < 0.01) & (df_ct1_vs_rest['logf2_'+name_cell_type1] > 0)]\n",
    "    df_ct2_vs_rest = df[['gene_'+name_cell_type2,'pval_adj_'+name_cell_type2,'logf2_'+name_cell_type2]]\n",
    "    df_ct2_vs_rest = df_ct2_vs_rest[(df_ct2_vs_rest['pval_adj_'+name_cell_type2] < 0.01) & (df_ct2_vs_rest['logf2_'+name_cell_type2] > 0)]\n",
    "\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', groups = [leidcl1[0]], reference = leidcl2[0], method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes = 99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    genes.rename(columns = {leidcl1[0]:'gene'},inplace=True)\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    pvals_adj.rename(columns = {leidcl1[0]:'pval_adj'},inplace=True)\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    logf2.rename(columns = {leidcl1[0]:'logf2'},inplace=True)\n",
    "    df_ct1_vs_ct2 = pd.concat([genes,pvals_adj,logf2],axis=1)\n",
    "    df_ct1_vs_ct2 = df_ct1_vs_ct2[df_ct1_vs_ct2['pval_adj'] < 0.01]\n",
    "    \n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    mg_ct1 = df_mg.index[df_mg[name_cell_type1]>0].tolist()\n",
    "    mg_ct2 = df_mg.index[df_mg[name_cell_type2]>0].tolist()\n",
    "    mg_overlap = [x for x in mg_ct1 if x in mg_ct2]\n",
    "    df_overlap = df_ct1_vs_ct2[df_ct1_vs_ct2['gene'].isin(mg_overlap)]\n",
    "    candidates_ct1 = df_overlap[df_overlap['logf2']>0]['gene'].to_list()\n",
    "    candidates_ct2 = df_overlap[df_overlap['logf2']<0]['gene'].to_list()\n",
    "    drop_ct2 = []\n",
    "    if len(candidates_ct1)>0:\n",
    "        reject1 = df_ct2_vs_rest[df_ct2_vs_rest['gene_'+name_cell_type2].isin(candidates_ct1)]['gene_'+name_cell_type2].to_list()\n",
    "        drop_ct2 = [x for x in candidates_ct1 if x not in reject1]    \n",
    "    drop_ct1 = []\n",
    "    if len(candidates_ct2)>0:\n",
    "        reject2 = df_ct1_vs_rest[df_ct1_vs_rest['gene_'+name_cell_type1].isin(candidates_ct2)]['gene_'+name_cell_type1].to_list()\n",
    "        drop_ct1 = [x for x in candidates_ct2 if x not in reject2]\n",
    "    results = {'DEGs': df_ct1_vs_ct2, 'DEGs_'+name_cell_type1+'_vs_rest': df_ct1_vs_rest, 'DEGs_'+name_cell_type2+'_vs_rest': df_ct2_vs_rest, 'markers_'+name_cell_type1: mg_ct1, 'markers_'+name_cell_type2: mg_ct2, 'overlap_markers': mg_overlap, 'drop_'+name_cell_type1: drop_ct1, 'drop_'+name_cell_type2: drop_ct2}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEGs_between_each_leiden_cluster_and_rest_compared_to_markers(adata,name_cell_types, putative_leiden_clusters_per_cell_type, path_mg)->dict:\n",
    "    a = adata.obs['leiden']\n",
    "    leidcl = []\n",
    "    for putative_leiden_clusters in putative_leiden_clusters_per_cell_type:\n",
    "        L = [str(x) for x in putative_leiden_clusters]\n",
    "        for n in L:\n",
    "            a = a.replace(n,L[0])\n",
    "        leidcl.append(L[0])\n",
    "    adata.obs['leiden_mod'] = a\n",
    "    #adata.uns['log1p'][\"base\"] = None\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes=99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    dict_df_ct_vs_rest = {}\n",
    "    dict_ct_markers = {}\n",
    "    dict_ct_pos_DEG_but_not_marker = {}\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    i = 0\n",
    "    for nr in leidcl:\n",
    "        df_ct_vs_rest = pd.concat([genes[[nr]],pvals_adj[[nr]],logf2[[nr]]],axis=1)\n",
    "        # change column names of df_ct_vs_rest\n",
    "        df_ct_vs_rest.columns = ['gene','pvals_adj','logf2']\n",
    "        df_ct_vs_rest = df_ct_vs_rest[df_ct_vs_rest['pvals_adj'] < 0.01]\n",
    "        dict_df_ct_vs_rest[name_cell_types[i]] = df_ct_vs_rest\n",
    "        if name_cell_types[i] != 'Unknown':\n",
    "            markers_ct = df_mg.index[df_mg[name_cell_types[i]]>0].tolist()\n",
    "        else:\n",
    "            markers_ct = []\n",
    "        dict_ct_markers[name_cell_types[i]] = markers_ct\n",
    "        pos_DEGs_but_no_mg = df_ct_vs_rest[(~df_ct_vs_rest['gene'].isin(markers_ct)) & (df_ct_vs_rest['logf2'] > 0)]\n",
    "        dict_ct_pos_DEG_but_not_marker[name_cell_types[i]] = pos_DEGs_but_no_mg\n",
    "        i = i + 1\n",
    "   \n",
    "    results = {'DEGs': dict_df_ct_vs_rest, 'markers': dict_ct_markers, 'pos_DEGs_but_not_marker': dict_ct_pos_DEG_but_not_marker}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(list1,list2):\n",
    "    list1 = np.ceil(list1)\n",
    "    list2 = np.ceil(list2)\n",
    "    # list1 AND list2\n",
    "    list3 = [list1[i] and list2[i] for i in range(len(list1))]\n",
    "    list4 = [list1[i] or list2[i] for i in range(len(list1))]\n",
    "    Jaccard = np.sum(list3)/np.sum(list4)\n",
    "    return np.round(Jaccard,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_similarity_matrix(path_mg):\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    Jaccard_sim = pd.DataFrame(index=df_mg.columns, columns=df_mg.columns)\n",
    "    for i in df_mg.columns:\n",
    "        for j in df_mg.columns:\n",
    "            Jaccard_sim.loc[i,j] = Jaccard(df_mg[i].to_list(),df_mg[j].to_list())\n",
    "    Jaccard_sim = Jaccard_sim.astype(float)\n",
    "    sns.heatmap(Jaccard_sim,annot=True)\n",
    "    print(df_mg.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_1(adata,cell_types,leiden_clusters,path_mg)->dict:\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    n_ct = len(cell_types)\n",
    "    marker_gene_drop = {}\n",
    "    details_DEGs = {}\n",
    "    for i in range(n_ct):\n",
    "        for j in range(i+1,n_ct):            \n",
    "            d = DEGs_between_2_sets_leiden_clusters_compared_to_markers(adata,cell_types[i],leiden_clusters[i],cell_types[j],leiden_clusters[j],path_mg)\n",
    "            details_DEGs[cell_types[i]+'_'+cell_types[j]] = d\n",
    "            if len(d['drop_'+cell_types[i]])>0:\n",
    "                for g in d['drop_'+cell_types[i]]:\n",
    "                    if df_mg.loc[g,cell_types[i]] >= df_mg.loc[g,cell_types[j]]:\n",
    "                        if cell_types[i] in marker_gene_drop:\n",
    "                            marker_gene_drop[cell_types[i]].append([g,cell_types[j]])\n",
    "                        else:\n",
    "                            marker_gene_drop[cell_types[i]] = []\n",
    "                            marker_gene_drop[cell_types[i]].append([g,cell_types[j]])\n",
    "            if len(d['drop_'+cell_types[j]])>0:\n",
    "                for g in d['drop_'+cell_types[j]]:\n",
    "                    if df_mg.loc[g,cell_types[j]] >= df_mg.loc[g,cell_types[i]]:\n",
    "                        if cell_types[j] in marker_gene_drop:\n",
    "                            marker_gene_drop[cell_types[j]].append([g,cell_types[i]])\n",
    "                        else:\n",
    "                            marker_gene_drop[cell_types[j]] = []\n",
    "                            marker_gene_drop[cell_types[j]].append([g,cell_types[i]])\n",
    "    print('Summary:')\n",
    "    for key in marker_gene_drop.keys():\n",
    "        print(key)\n",
    "        print('Maybe drop:'+str(marker_gene_drop[key]))\n",
    "    return marker_gene_drop, details_DEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_2(adata,cell_types,leiden_clusters,path_mg)->(dict,dict):\n",
    "    dict_DEGs = DEGs_between_each_leiden_cluster_and_rest_compared_to_markers(adata,cell_types,leiden_clusters,path_mg)\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    genes = adata.var_names\n",
    "    marker_genes = df_mg.index.tolist()\n",
    "    marker_gene_add = {}\n",
    "    for gene in genes:\n",
    "        candidates = []\n",
    "        for i in cell_types:\n",
    "            if gene in dict_DEGs['pos_DEGs_but_not_marker'][i]['gene'].tolist():\n",
    "                candidates.append(i)\n",
    "                if i in marker_gene_add:\n",
    "                    marker_gene_add[i].append(gene)\n",
    "                else:\n",
    "                    marker_gene_add[i] = [gene]\n",
    "        if(len(candidates) > 0):\n",
    "            print(gene)\n",
    "            if gene in marker_genes:\n",
    "                a = df_mg.loc[gene,:]\n",
    "                b = a[a>0].index.values\n",
    "                print('Is marker gene of: '+str(b.tolist()))\n",
    "                print('Could also be a marker gene of: '+str(candidates))\n",
    "            else:\n",
    "                print('Is marker gene of: []')\n",
    "                print('Could also be a marker gene of: '+str(candidates))\n",
    "    print('Summary:')\n",
    "    for key in marker_gene_add.keys():\n",
    "        print(key)\n",
    "        print('Maybe add:'+str(marker_gene_add[key]))\n",
    "    return marker_gene_add, dict_DEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_multiple_times(adata,cell_types,leiden_clusters,path_mg,N,strategy):\n",
    "    results_runs = {}\n",
    "    DEG_details_runs = {}\n",
    "    Not_considered_celltypes = []\n",
    "    Not_considered_leiden_clusters = []\n",
    "\n",
    "    nr_cells_of_each_cons_ct = []\n",
    "    for i in range(len(cell_types)):\n",
    "        if len(leiden_clusters[i])>0 and cell_types[i] != 'Unknown':\n",
    "            leiden_cl = [str(x) for x in leiden_clusters[i]]\n",
    "            leiden = adata[adata.obs['leiden'].isin(leiden_cl),:]\n",
    "            nr_cells_of_each_cons_ct.append(len(leiden))\n",
    "\n",
    "    n_cells = min(nr_cells_of_each_cons_ct)\n",
    "\n",
    "    print(n_cells)\n",
    "\n",
    "    for k in range(N):\n",
    "        list_sub_anndata = []\n",
    "        for i in range(len(cell_types)):\n",
    "            if len(leiden_clusters[i])>0 and cell_types[i] != 'Unknown':\n",
    "                leiden_cl = [str(x) for x in leiden_clusters[i]]\n",
    "                leiden = adata[adata.obs['leiden'].isin(leiden_cl),:]\n",
    "                leiden_cells = leiden.obs.index.to_list()\n",
    "                leiden_cells_random = sample(leiden_cells,n_cells)\n",
    "                leiden = leiden[leiden_cells_random,:]\n",
    "                list_sub_anndata.append(leiden)\n",
    "            else:\n",
    "                Not_considered_celltypes.append(cell_types[i])\n",
    "                if leiden_clusters[i] not in Not_considered_leiden_clusters:\n",
    "                    Not_considered_leiden_clusters.append(leiden_clusters[i])\n",
    "        cell_types = [x for x in cell_types if x not in Not_considered_celltypes]\n",
    "        leiden_clusters = [x for x in leiden_clusters if x not in Not_considered_leiden_clusters]\n",
    "        sub_anndata = ad.concat(list_sub_anndata)\n",
    "        if strategy == 1:\n",
    "            results_runs[k],DEG_details_runs[k] = Apply_strategy_1(sub_anndata,cell_types,leiden_clusters,path_mg)\n",
    "        if strategy == 2:\n",
    "            results_runs[k],DEG_details_runs[k] = Apply_strategy_2(sub_anndata,cell_types,leiden_clusters,path_mg)\n",
    "\n",
    "    counts_run = {}\n",
    "    for key in results_runs.keys():\n",
    "        for k in results_runs[key].keys():\n",
    "            if k not in counts_run.keys():\n",
    "                counts_run[k] = results_runs[key][k]\n",
    "            else:\n",
    "                for i in results_runs[key][k]:\n",
    "                    counts_run[k].append(i)\n",
    "    final = {}\n",
    "    for key in counts_run:\n",
    "        df = pd.DataFrame(counts_run[key]).value_counts()\n",
    "        # keep rows with value > N/2\n",
    "        print(df)\n",
    "        df = df[df > N/2]\n",
    "        final[key] = df.index.to_list()\n",
    "\n",
    "    colors = []\n",
    "    for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "    for c in plt.cm.tab20b.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "\n",
    "    print('Cell types that are not considered: '+str(Not_considered_celltypes))\n",
    "    print('Cells of each cell type that are compared in each run: '+str(n_cells))\n",
    "\n",
    "    if strategy == 1:\n",
    "        sign_tuples = []\n",
    "        for key in final.keys():\n",
    "            for t in final[key]:\n",
    "                sign_tuples.append((key,t))\n",
    "        sign_tuples = [(x[0],x[1][0],x[1][1]) for x in sign_tuples]\n",
    "\n",
    "        DEGs_runs = {} \n",
    "        DEGs_runs_sign = {}\n",
    "        n_ct = len(cell_types)\n",
    "        for r in range(N):\n",
    "            dfs = []\n",
    "            for i in range(n_ct):\n",
    "                for j in range(i+1,n_ct):\n",
    "                    if cell_types[i] != 'Unknown' and cell_types[j] != 'Unknown':\n",
    "                        df = DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['DEGs']\n",
    "                        df['ct1'] = cell_types[i]\n",
    "                        df['ct2'] = cell_types[j]\n",
    "                        # only keep rows with value of gene in overlap_markers\n",
    "                        df = df[df['gene'].isin(DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['overlap_markers'])]\n",
    "                        # only keep rows if gene is not sign expressed vs the rest in cell type with smaller expression (see def strategy 1)\n",
    "                        ct1_sign_vs_rest = DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['DEGs_'+cell_types[i]+'_vs_rest']['gene_'+cell_types[i]].to_list()\n",
    "                        ct2_sign_vs_rest = DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['DEGs_'+cell_types[j]+'_vs_rest']['gene_'+cell_types[j]].to_list()\n",
    "                        genes = df['gene'].to_list()\n",
    "                        for g in genes:\n",
    "                            # get logf2 of row in df with gene equal to g\n",
    "                            logf2 = df[df['gene']==g]['logf2'].to_list()[0]\n",
    "                            if logf2 > 0:\n",
    "                                if g in ct2_sign_vs_rest:\n",
    "                                    df = df[df['gene'] != g]\n",
    "                            else:\n",
    "                                if g in ct1_sign_vs_rest:\n",
    "                                    df = df[df['gene'] != g]\n",
    "                        dfs.append(df)                 \n",
    "            DEGs_runs[r] = pd.concat(dfs)\n",
    "            \n",
    "            s = []\n",
    "            s.append(DEGs_runs[r].merge(pd.DataFrame(sign_tuples, columns=['ct1','gene','ct2'])))\n",
    "            s.append(DEGs_runs[r].merge(pd.DataFrame(sign_tuples, columns=['ct2','gene','ct1'])))\n",
    "            DEGs_runs_sign[r] = pd.concat(s)\n",
    "\n",
    "        all_together = []\n",
    "        for r in range(N):\n",
    "            all_together.append(DEGs_runs[r])\n",
    "        df_all_together = pd.concat(all_together)\n",
    "\n",
    "        all_together_sign = []\n",
    "        all_together_sign.append(df_all_together.merge(pd.DataFrame(sign_tuples, columns=['ct1','gene','ct2'])))\n",
    "        all_together_sign.append(df_all_together.merge(pd.DataFrame(sign_tuples, columns=['ct2','gene','ct1'])))\n",
    "        df_all_together_sign = pd.concat(all_together_sign)\n",
    "\n",
    "        logpadj_min_plot = df_all_together['pval_adj'].min()/10\n",
    "        logpadj_max_plot = 0.5\n",
    "        logf2_max_plot = df_all_together['logf2'].max() + 0.2\n",
    "        logf2_min_plot = df_all_together['logf2'].min() - 0.2\n",
    "\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in DEGs_runs.keys():\n",
    "            ax.scatter(DEGs_runs[run]['pval_adj'].to_list(),DEGs_runs[run]['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in DEGs_runs_sign.keys():\n",
    "            ax.scatter(DEGs_runs_sign[run]['pval_adj'].to_list(),DEGs_runs_sign[run]['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for i in range(n_ct):\n",
    "                for j in range(n_ct):\n",
    "                    df = df_all_together[df_all_together['ct1'] == cell_types[i]]\n",
    "                    df = df[df['ct2'] == cell_types[j]]\n",
    "                    if len(df) > 0:\n",
    "                        ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=cell_types[i]+'_'+cell_types[j],c=colors[c])\n",
    "                        c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for i in range(n_ct):\n",
    "                for j in range(n_ct):\n",
    "                    df = df_all_together_sign[df_all_together_sign['ct1'] == cell_types[i]]\n",
    "                    df = df[df['ct2'] == cell_types[j]]\n",
    "                    if(len(df) > 0):\n",
    "                        ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=cell_types[i]+'_'+cell_types[j],c=colors[c])\n",
    "                        c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        genes_all = df_all_together['gene'].unique()\n",
    "        genes_all_sets = []\n",
    "        for i in range(0,len(genes_all),10):\n",
    "                    genes_all_sets.append(genes_all[i:i+10])\n",
    "                \n",
    "        for genes in genes_all_sets:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for i in range(n_ct):\n",
    "                for j in range(i+1,n_ct):            \n",
    "                    for g in genes:\n",
    "                        df = df_all_together[df_all_together['ct1'] == cell_types[i]]\n",
    "                        df = df[df['ct2'] == cell_types[j]]\n",
    "                        df = df[df['gene'] == g]\n",
    "                        if len(df) > 0:\n",
    "                            ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=g + ' ('+cell_types[i]+'_'+cell_types[j]+')',c=colors[c])\n",
    "                            c = (c + 1)%40\n",
    "            ax.legend()\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "            ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "            ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_found_strategy_1')\n",
    "            plt.show()\n",
    "\n",
    "        genes_all_sign = df_all_together_sign['gene'].unique()\n",
    "        genes_all_sets_sign = []\n",
    "        for i in range(0,len(genes_all_sign),20):\n",
    "                    genes_all_sets_sign.append(genes_all_sign[i:i+20])\n",
    "                \n",
    "        for genes in genes_all_sets_sign:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for i in range(n_ct):\n",
    "                for j in range(i+1,n_ct):            \n",
    "                    for g in genes:\n",
    "                        df = df_all_together[df_all_together['ct1'] == cell_types[i]]\n",
    "                        df = df[df['ct2'] == cell_types[j]]\n",
    "                        df = df[df['gene'] == g]\n",
    "                        if len(df) > 0:\n",
    "                            ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=g + ' ('+cell_types[i]+'_'+cell_types[j]+')',c=colors[c])\n",
    "                            c = (c + 1)%40\n",
    "            ax.legend()\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "            ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "            ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_kept_strategy_1')\n",
    "            plt.show()\n",
    "        \n",
    "        genes_drop = []\n",
    "        for keys in final.keys():\n",
    "            for g in final[keys]:\n",
    "                if g[0] not in genes_drop:\n",
    "                    genes_drop.append(g[0])\n",
    "        sc.pl.heatmap(adata,var_names=genes_drop,groupby='leiden_cell_types',standard_scale='var')\n",
    "        adata_sub = adata[~(adata.obs['leiden_cell_types']=='Hepa'),:]\n",
    "        sc.pl.heatmap(adata_sub,var_names=genes_drop,groupby='leiden_cell_types',standard_scale='var')\n",
    "\n",
    "    if strategy == 2:\n",
    "        for key in final.keys():\n",
    "            final[key] = [i[0] for i in final[key]]\n",
    "\n",
    "        sign_tuples = []\n",
    "        for key in final.keys():\n",
    "            for g in final[key]:\n",
    "                sign_tuples.append((g,key))\n",
    "\n",
    "        DEGs_runs_all_cell_types_together = {}\n",
    "        for i in range(N):\n",
    "            dfs = []\n",
    "            for ct in cell_types:\n",
    "                df = DEG_details_runs[i]['pos_DEGs_but_not_marker'][ct]\n",
    "                # add column to df with cell type\n",
    "                df['cell_type'] = ct\n",
    "                dfs.append(df)\n",
    "            # concatenate all dataframes in dfs\n",
    "            DEGs_runs_all_cell_types_together[i] = pd.concat(dfs)\n",
    "        all_together = []\n",
    "        for i in range(N):\n",
    "            all_together.append(DEGs_runs_all_cell_types_together[i])\n",
    "        df_all_together = pd.concat(all_together)\n",
    "        df_all_together_sign = df_all_together.merge(pd.DataFrame(sign_tuples, columns=['gene','cell_type']))  \n",
    "        genes_all = df_all_together['gene'].unique()\n",
    "        genes_all_sign = df_all_together_sign['gene'].unique()\n",
    "\n",
    "        logpadj_min_plot = df_all_together['pvals_adj'].min()/10\n",
    "        logpadj_max_plot = 0.5\n",
    "        logf2_max_plot = df_all_together['logf2'].max() + 0.2\n",
    "        logf2_min_plot = -0.2\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in DEGs_runs_all_cell_types_together:\n",
    "            ax.scatter(DEGs_runs_all_cell_types_together[run]['pvals_adj'].to_list(),DEGs_runs_all_cell_types_together[run]['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in range(N):\n",
    "            df = DEGs_runs_all_cell_types_together[run].merge(pd.DataFrame(sign_tuples, columns=['gene','cell_type']))        \n",
    "            ax.scatter(df['pvals_adj'].to_list(),df['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for ct in cell_types:\n",
    "            # select only the rows of the cell type\n",
    "            df = df_all_together[df_all_together['cell_type'] == ct]\n",
    "            ax.scatter(df['pvals_adj'].to_list(),df['logf2'].to_list(), label=str(ct),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0 \n",
    "        for ct in cell_types:\n",
    "            # select only the rows of the cell type\n",
    "            df = df_all_together_sign[df_all_together_sign['cell_type'] == ct]\n",
    "            ax.scatter(df['pvals_adj'].to_list(),df['logf2'].to_list(), label=ct, c = colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        genes_all_sets = []\n",
    "        for i in range(0,len(genes_all),10):\n",
    "            genes_all_sets.append(genes_all[i:i+10])\n",
    "        for genes in genes_all_sets:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for gene in genes:\n",
    "                # select only the rows of the cell type\n",
    "                df = df_all_together[df_all_together['gene'] == gene]\n",
    "                # get unique cell_types in df\n",
    "                cell_types = df['cell_type'].unique()\n",
    "                for ct in cell_types:\n",
    "                    df_ct = df[df['cell_type'] == ct]\n",
    "                    ax.scatter(df_ct['pvals_adj'].to_list(),df_ct['logf2'].to_list(), label=gene + ' ('+ct+')',c=colors[c])\n",
    "                    c = (c + 1)%40\n",
    "            # Shrink current axis by 20%\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            # Put a legend to the right of the current axis\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_found_strategy_2')\n",
    "            plt.show()\n",
    "\n",
    "        genes_all_sets = []\n",
    "        for i in range(0,len(genes_all_sign),10):\n",
    "            genes_all_sets.append(genes_all_sign[i:i+10])\n",
    "        for genes in genes_all_sets:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for gene in genes:\n",
    "                # select only the rows of the cell type\n",
    "                df = df_all_together_sign[df_all_together_sign['gene'] == gene]\n",
    "                # get unique cell_types in df\n",
    "                cell_types = df['cell_type'].unique()\n",
    "                for ct in cell_types:\n",
    "                    df_ct = df[df['cell_type'] == ct]\n",
    "                    ax.scatter(df_ct['pvals_adj'].to_list(),df_ct['logf2'].to_list(), label=gene + ' ('+ct+')',c=colors[c])\n",
    "                    c = (c + 1)%40\n",
    "            # Shrink current axis by 20%\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            # Put a legend to the right of the current axis\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_kept_strategy_2')\n",
    "            plt.show()\n",
    "\n",
    "        genes_add = []\n",
    "        for keys in final.keys():\n",
    "            for g in final[keys]:\n",
    "                if g not in genes_add:\n",
    "                    genes_add.append(g)\n",
    "\n",
    "        sc.pl.heatmap(adata,var_names=genes_add,groupby='leiden_cell_types',standard_scale='var')\n",
    "        adata_sub = adata[~(adata.obs['leiden_cell_types']=='Hepa'),:]\n",
    "        sc.pl.heatmap(adata_sub,var_names=genes_add,groupby='leiden_cell_types',standard_scale='var')\n",
    "\n",
    "    return final, results_runs, DEG_details_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringVSleiden(adata, celltype_column, leiden_column, cell_types):\n",
    "      \n",
    "    stacked = (\n",
    "            adata.obs.groupby([leiden_column, celltype_column], as_index=False)\n",
    "            .size()\n",
    "            .pivot(leiden_column, celltype_column)\n",
    "            .fillna(0)\n",
    "        )\n",
    "    stacked_norm = stacked.div(stacked.sum(axis=1), axis=0)\n",
    "    stacked_norm.columns = [x[1] for x in stacked_norm.columns]\n",
    "    stacked_norm.index = [(x,adata.obs[leiden_column].value_counts()[x]) for x in stacked_norm.index]\n",
    "\n",
    "    print(stacked_norm.columns) \n",
    "\n",
    "    # get max of each row\n",
    "    max = stacked_norm.max(axis=1)\n",
    "    # get column with max value of each row\n",
    "    max_col = stacked_norm.idxmax(axis=1)\n",
    "\n",
    "    dict_leiden_clusters_per_ct = {}\n",
    "    for i in range(len(stacked_norm)):\n",
    "        if max[i]>0.5:\n",
    "            if max_col[i] not in dict_leiden_clusters_per_ct.keys():\n",
    "                dict_leiden_clusters_per_ct[max_col[i]] = []\n",
    "            dict_leiden_clusters_per_ct[max_col[i]].append(i)\n",
    "        else:\n",
    "            if 'Unknown' not in dict_leiden_clusters_per_ct.keys():\n",
    "                dict_leiden_clusters_per_ct['Unknown'] = []\n",
    "            dict_leiden_clusters_per_ct['Unknown'].append(i)\n",
    "    \n",
    "    leiden_clusters_per_cell_type = []\n",
    "\n",
    "    for ct in cell_types:\n",
    "        if ct not in dict_leiden_clusters_per_ct.keys():\n",
    "            leiden_clusters_per_cell_type.append([])\n",
    "        else:\n",
    "            leiden_clusters_per_cell_type.append(dict_leiden_clusters_per_ct[ct])\n",
    "\n",
    "    for i in range(len(cell_types)):\n",
    "        print(cell_types[i])\n",
    "        print(leiden_clusters_per_cell_type[i])\n",
    "\n",
    "    for i in range(0,len(stacked_norm),35):\n",
    "        st_n = stacked_norm.iloc[i:i+35,:]\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        st_n.plot(kind=\"bar\", stacked=True, ax=fig.gca())\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_visible(False)\n",
    "        ax.spines[\"left\"].set_visible(False)\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "        plt.xlabel(\"Clusters\")\n",
    "        plt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5), fontsize=\"large\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    return leiden_clusters_per_cell_type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
