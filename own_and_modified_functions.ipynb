{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the value of the environment variable BASIC_DCT_BACKEND is not in [\"JAX\",\"SCIPY\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import napari_sparrow as nas\n",
    "from spatialdata import read_zarr\n",
    "import os\n",
    "import scanpy as sc\n",
    "from spatialdata import SpatialData\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from napari_sparrow.table._table import _back_sdata_table_to_zarr\n",
    "from napari_sparrow.table._annotation import _annotate_celltype\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import anndata as ad\n",
    "from random import sample \n",
    "import seaborn as sns\n",
    "import matplotlib \n",
    "import matplotlib.ticker as ticker\n",
    "import squidpy as sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_atlas_percentages = pd.read_csv(\"/home/wout/Documents/Thesis_lokaal/Mouse_Liver_Resolve_Data/basic_annotation_percentage_atlas.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_umap(anndata,n_PCAs,n_neighbors):\n",
    "    sc.pp.neighbors(anndata, n_neighbors=n_neighbors, n_pcs=n_PCAs)\n",
    "    sc.tl.umap(anndata)\n",
    "    anndata.uns['umap_'+str(n_neighbors)] = anndata.uns['umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification(anndata,classification_name,umap_name,path_mg,plot_umap=True,plot_dot_plot=True,plot_rank_genes_groups=True,plot_cluster_homogeneity=True,plot_corr_scores=True,plot_count_dens=True):\n",
    "    # Plot the UMAP\n",
    "    if plot_umap:\n",
    "        anndata.uns['umap'] = anndata.uns[umap_name]\n",
    "        sc.pl.umap(anndata,color=[\"annotation_\"+classification_name])\n",
    "    \n",
    "    # Give the cell type proportions\n",
    "    df_prediction = pd.DataFrame(anndata.obs[\"annotation_\"+classification_name].value_counts(normalize=True))\n",
    "    df_prediction.sort_index(inplace=True)\n",
    "    df_pred = df_prediction * 100\n",
    "    print(\"Cell type proportions:\")\n",
    "    print(df_pred.round(6).abs())\n",
    "    print(\"\\n\")\n",
    "    print(\"Leiden clusters\")\n",
    "    print(\"Only a cell type assigned to a Leiden cluster, if more than 50 percent of cells have the same cell type, otherwise 'Unknown':\")\n",
    "    if plot_cluster_homogeneity:\n",
    "        clusteringVSleiden(anndata, \"annotation_\"+classification_name, \"leiden\", cell_types = 'all', print_results=True)\n",
    "    fr_cells_unknown = compare_annotations_samples_cluster_homogeneity_percentage_unknown([anndata],[\"\"],[\"annotation_\"+classification_name],[\"\"],plot=False)\n",
    "    print(\"Fraction of cells in a Leiden cluster with unknown cell type:\")\n",
    "    print(fr_cells_unknown[0][0].round(3))\n",
    "    average_homog = compare_annotations_samples_cluster_homogeneity([anndata],[\"\"],[\"annotation_\"+classification_name],[\"\"],plot=False)\n",
    "    print(\"Average cluster homogeneity:\")\n",
    "    print(average_homog[0][0].round(3))\n",
    "    cell_types, all_homog_per_ct = compare_annotations_cluster_homogeneity(anndata,[\"\"],[\"annotation_\"+classification_name],[\"\"],plot=False)\n",
    "    print(\"Average cluster homogeneity per cell_type:\")\n",
    "    for i in range(len(cell_types)):\n",
    "        print(cell_types[i] + \": \" + str(all_homog_per_ct[i][0].round(3)))\n",
    "    print(\"\\n\")\n",
    "    print(\"Correlation between cell type scores:\")\n",
    "    scores = anndata.uns[classification_name]\n",
    "    corr_matrix = scores.corr(method='pearson')\n",
    "    #mean_corr = corr_matrix.mean().mean()\n",
    "    if plot_corr_scores:\n",
    "        sns.heatmap(np.round(corr_matrix,2), annot=True)\n",
    "        plt.show()\n",
    "    #print(\"Mean correlation between scores of cell types: \" + str(mean_corr.round(3)))\n",
    "    \n",
    "    if plot_count_dens:\n",
    "        sns.violinplot(data=anndata.obs,x=\"total_counts\",y=\"annotation_\" + classification_name)\n",
    "        plt.show()\n",
    "        sns.violinplot(data=anndata.obs,x=\"shapeSize\",y=\"annotation_\" + classification_name)\n",
    "        plt.show()\n",
    "        anndata.obs['count_density'] = anndata.obs['total_counts'] / anndata.obs['shapeSize']\n",
    "        sns.violinplot(data=anndata.obs,x=\"count_density\",y=\"annotation_\" + classification_name)\n",
    "        plt.show()\n",
    "\n",
    "    # Plot expression of the marker genes for each cluster\n",
    "    if plot_dot_plot:\n",
    "        make_dot_plot(anndata,path_mg,classification_dot_plot=\"annotation_\"+classification_name)\n",
    "\n",
    "    # Plot the highly differential genes for each cluster\n",
    "    if plot_rank_genes_groups:\n",
    "        anndata.uns['log1p'][\"base\"] = None\n",
    "        sc.tl.rank_genes_groups(anndata, groupby=\"annotation_\"+classification_name,key=\"annotation_\"+classification_name+'_rank_genes')\n",
    "        sc.pl.rank_genes_groups(anndata, n_genes=8, sharey=False, show=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dot plot\n",
    "def make_dot_plot(anndata,path_mg,classification_dot_plot):\n",
    "    marker_genes = pd.read_csv(path_mg, sep=',', index_col=0)\n",
    "    cell_types = marker_genes.columns \n",
    "    df_backup = anndata.var.copy(deep=True)     \n",
    "    all_genes = anndata.var.index.str.capitalize()\n",
    "    for gene in all_genes:\n",
    "        if gene not in marker_genes.index:\n",
    "            marker_genes.loc[gene] = [0]*len(marker_genes.columns)  \n",
    "    marker_genes.sort_index(inplace=True) \n",
    "    anndata.var = anndata.var.join(marker_genes)\n",
    "    anndata.var['sum'] = anndata.var.iloc[:,len(anndata.var.columns)-len(cell_types):len(anndata.var.columns)].sum(axis=1)\n",
    "    positions_labels_dict = {}\n",
    "    for cell_type in cell_types:\n",
    "        positions = np.where(anndata.var[cell_type]>0)[0]\n",
    "        for p in positions:\n",
    "            if (p,p) in positions_labels_dict:\n",
    "                positions_labels_dict[(p,p)] = positions_labels_dict[(p,p)] + '_' + cell_type.lower()\n",
    "            else:\n",
    "                positions_labels_dict[(p,p)] = cell_type.lower()\n",
    "    keys = positions_labels_dict.keys()\n",
    "    values = positions_labels_dict.values()    \n",
    "    sc.pl.dotplot(anndata,var_names=anndata.var_names,groupby=classification_dot_plot,dendrogram=True,var_group_positions=list(keys),var_group_labels=list(values))    \n",
    "    anndata.var = df_backup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_celltype_score_genes_bins(anndata,celltypes,row_norm = False, celltype_column = \"annotation\"):\n",
    "    scoresper_cluster = anndata.obs[\n",
    "        [col for col in anndata.obs if col in celltypes]\n",
    "    ]\n",
    "\n",
    "    if row_norm:\n",
    "        row_norm = scoresper_cluster.sub(\n",
    "            scoresper_cluster.mean(axis=1).values, axis=\"rows\"\n",
    "        ).div(scoresper_cluster.std(axis=1).values, axis=\"rows\")\n",
    "        anndata.obs[scoresper_cluster.columns.values] = row_norm\n",
    "        temp = pd.DataFrame(np.sort(row_norm)[:, -2:])\n",
    "    else:\n",
    "        temp = pd.DataFrame(np.sort(scoresper_cluster)[:, -2:])\n",
    "\n",
    "\n",
    "    scores = (temp[1] - temp[0]) / ((temp[1] + temp[0]) / 2)\n",
    "    anndata.obs[\"Cleanliness\"] = scores.values\n",
    "\n",
    "    def assign_cell_type(row):\n",
    "        # Identify the cell type with the max score\n",
    "        max_score_type = row.idxmax()\n",
    "        # If max score is <= 0, assign 'unknown_celltype'\n",
    "        if row[max_score_type] <= 0:\n",
    "            return \"unknown_celltype\"\n",
    "        else:\n",
    "            return max_score_type\n",
    "\n",
    "    # Assign 'unknown_celltype' cell_type if no cell type could be found that has larger expression than random sample\n",
    "    # as calculated by sc.tl.score_genes function of scanpy.\n",
    "    anndata.obs[celltype_column] = scoresper_cluster.apply(assign_cell_type, axis=1)\n",
    "    anndata.obs[celltype_column] = anndata.obs[celltype_column].astype(\n",
    "        \"category\"\n",
    "    )\n",
    "    # Set the Cleanliness score for unknown_celltype equal to 0 (i.e. not clean)\n",
    "    anndata.obs.loc[\n",
    "        anndata.obs[celltype_column] == \"unknown_celltype\", \"Cleanliness\"\n",
    "    ] = 0\n",
    "\n",
    "    return anndata, scoresper_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_genes_bins(\n",
    "    anndata,\n",
    "    path_marker_genes: str,\n",
    "    bins: int = 25,\n",
    "    delimiter=\",\",\n",
    "    row_norm: bool = False,\n",
    "    repl_columns: Optional[Dict[str, str]] = None,\n",
    "    del_celltypes: Optional[List[str]] = None,\n",
    "    input_dict=False,\n",
    "    suffix = \"\",\n",
    ") -> Tuple[dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    The function loads marker genes from a CSV file and scores cells for each cell type using those markers\n",
    "    using scanpy's score_genes function.\n",
    "    Marker genes can be provided as a one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column;\n",
    "    or in dictionary format. The function further allows replacements of column names and deletions of specific marker genes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sdata : SpatialData\n",
    "        Data containing spatial information.\n",
    "    path_marker_genes : str\n",
    "        Path to the CSV file containing the marker genes.\n",
    "        CSV file should be a one-hot encoded matrix with cell types listed in the first row, and marker genes in the first column.\n",
    "    bins : int, optional\n",
    "        Number of bins to use for the sc.tl.score_genes function, default is 25.\n",
    "    delimiter : str, optional\n",
    "        Delimiter used in the CSV file, default is ','.\n",
    "    row_norm : bool, optional\n",
    "        Flag to determine if row normalization is applied, default is False.\n",
    "    repl_columns : dict, optional\n",
    "        Dictionary containing cell types to be replaced. The keys are the original cell type names and\n",
    "        the values are their replacements.\n",
    "    del_celltypes : list, optional\n",
    "        List of cell types to be deleted from the list of possible cell type candidates.\n",
    "        Cells are scored for these cell types, but will not be assigned a cell type from this list.\n",
    "    input_dict : bool, optional\n",
    "        If True, the marker gene list from the CSV file is treated as a dictionary with the first column being\n",
    "        the cell type names and the subsequent columns being the marker genes for those cell types. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with cell types as keys and their respective marker genes as values.\n",
    "    pd.DataFrame\n",
    "        Index:\n",
    "            cells: The index corresponds to indivdual cells ID's.\n",
    "        Columns:\n",
    "            celltypes (as provided via the markers file).\n",
    "        Values:\n",
    "            Score obtained using scanpy's score_genes function for each celltype and for each cell.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The cell type 'unknown_celltype' is reserved for cells that could not be assigned a specific cell type.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Load marker genes from csv\n",
    "    if input_dict:\n",
    "        df_markers = pd.read_csv(\n",
    "            path_marker_genes, header=None, index_col=0, delimiter=delimiter\n",
    "        )\n",
    "        df_markers = df_markers.T\n",
    "        genes_dict = df_markers.to_dict(\"list\")\n",
    "        for i in genes_dict:\n",
    "            genes_dict[i] = [x for x in genes_dict[i] if str(x) != \"nan\"]\n",
    "    # Replace column names in marker genes\n",
    "    else:\n",
    "        df_markers = pd.read_csv(path_marker_genes, index_col=0, delimiter=delimiter)\n",
    "        if repl_columns:\n",
    "            for column, replace in repl_columns.items():\n",
    "                df_markers.columns = df_markers.columns.str.replace(column, replace)\n",
    "\n",
    "        # Create genes dict with all marker genes for every celltype\n",
    "        genes_dict = {}\n",
    "        for i in df_markers:\n",
    "            genes = []\n",
    "            for row, value in enumerate(df_markers[i]):\n",
    "                if value > 0:\n",
    "                    genes.append(df_markers.index[row])\n",
    "            genes_dict[i] = genes\n",
    "\n",
    "    assert (\n",
    "        \"unknown_celltype\" not in genes_dict.keys()\n",
    "    ), \"Cell type 'unknown_celltype' is reserved for cells that could not be assigned a specific cell type\"\n",
    "\n",
    "    # Score all cells for all celltypes\n",
    "    for key, value in genes_dict.items():\n",
    "        try:\n",
    "            sc.tl.score_genes(anndata, value, score_name=key,n_bins=bins) # W: key = cell type, value = list of markergenes of that cell type\n",
    "        except ValueError:\n",
    "            log.warning(\n",
    "                f\"Markergenes {value} not present in region, celltype {key} not found\"\n",
    "            )\n",
    "\n",
    "    # Delete genes from marker genes and genes dict\n",
    "    if del_celltypes:\n",
    "        for gene in del_celltypes:\n",
    "            if gene in df_markers.columns:\n",
    "                del df_markers[gene]\n",
    "            if gene in genes_dict.keys():\n",
    "                del genes_dict[gene]\n",
    "\n",
    "    anndata, scoresper_cluster = annotate_celltype_score_genes_bins(anndata,celltypes=df_markers.columns,row_norm=row_norm,celltype_column=\"annotation\")\n",
    "\n",
    "    # add 'unknown_celltype' to the list of celltypes if it is detected.\n",
    "    if \"unknown_celltype\" in anndata.obs[\"annotation\"].cat.categories:\n",
    "        genes_dict[\"unknown_celltype\"] = []\n",
    "\n",
    "    name_clustering = 'score_genes_original' + suffix\n",
    "    anndata.uns[name_clustering] = scoresper_cluster\n",
    "    anndata.obs.rename(columns={'annotation': 'annotation_'+name_clustering}, inplace=True)\n",
    "    anndata.obs.rename(columns={'Cleanliness': 'cleanliness_'+name_clustering}, inplace=True)\n",
    "    # check if 'unknown_celltype' is a column of genes_dict\n",
    "    if 'unknown_celltype' in genes_dict:\n",
    "        del genes_dict['unknown_celltype']\n",
    "    anndata.obs.drop(genes_dict.keys(), axis=1, inplace=True)\n",
    "    cols = anndata.obs.columns.to_list()\n",
    "    cols_new = cols[0:len(cols)-2]\n",
    "    cols_new.append(cols[len(cols)-1])\n",
    "    cols_new.append(cols[len(cols)-2])\n",
    "    anndata.obs  = anndata.obs .reindex(columns=cols_new)\n",
    "    # replace 'unknown_celltype' by 'Unknown' in the annotation column\n",
    "    anndata.obs['annotation_'+name_clustering].replace({'unknown_celltype': 'Unknown'}, inplace=True)\n",
    "\n",
    "    #_back_sdata_table_to_zarr(sdata)\n",
    "\n",
    "    print((anndata.obs['annotation_score_genes_original'+suffix].value_counts()/len(anndata.obs['annotation_score_genes_original'+suffix]))*100)\n",
    "    sc.pl.umap(anndata,color=['annotation_score_genes_original'+suffix])\n",
    "\n",
    "    return genes_dict, scoresper_cluster\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_score_genes(anndata,path_mg,norm_expr_var=False,min_score='Zero',min_score_q=25,scale_score='MinMax',scale_score_q=1,suffix='',mean = 'all',mean_values = None)->pd.DataFrame: \n",
    "    # annotate each cell\n",
    "    # method based on score_genes of scanpy but no bins and min max normalization of the scores per cell type\n",
    "    # for each cell, a score is calculated for each cell type: \n",
    "    # sum of the expressions of the markers in the cell - sum of the mean expressions of the markers in all cells\n",
    "    # our expression data does not need to be scaled anymore (norm_expr_var = False) because sc.pp.scale is already applied in Sparrow\n",
    "    path_marker_genes = path_mg,\n",
    "    marker_genes = pd.read_csv(path_marker_genes[0], sep=',',index_col=0)\n",
    "    scores_cell_celltype = pd.DataFrame()\n",
    "    cell_types = marker_genes.columns.tolist()\n",
    "    matrix = anndata.to_df()\n",
    "    # correct for the variance of the expression of each gene\n",
    "    if norm_expr_var:\n",
    "        matrix = matrix.div(matrix.std(axis=0))\n",
    "    if mean == 'all':\n",
    "        mean_expression = matrix.mean(axis=0)\n",
    "    if mean == 'given':\n",
    "        mean_expression = mean_values\n",
    "    \n",
    "    matrix_minus_mean = matrix - mean_expression\n",
    "    genes_in_anndata = anndata.var_names.to_list()\n",
    "    Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "    ct = 0\n",
    "    for cell_type in cell_types:\n",
    "        anndata.obs['score_'+cell_type] = 0\n",
    "        for gene in marker_genes[marker_genes[cell_type] > 0].index.tolist():\n",
    "                if gene in genes_in_anndata:\n",
    "                    anndata.obs['score_'+cell_type] = anndata.obs['score_'+cell_type] + (matrix_minus_mean[gene]*marker_genes[cell_type][gene])/Nmarkers[ct]\n",
    "        scores_cell_celltype[cell_type] = anndata.obs['score_'+cell_type]\n",
    "        anndata.obs = anndata.obs.drop(columns=['score_'+cell_type])\n",
    "        ct = ct + 1\n",
    "    scores_cell_celltype.index.name = None\n",
    "    scores_cell_celltype = scores_cell_celltype.reset_index(drop=True)\n",
    "\n",
    "    # min score to obtain for a cell type, otherwise 'unknown' \n",
    "    if min_score == 'Zero':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok > 0] = True\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok != True] = False\n",
    "    if min_score == 'Quantile':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok > scores_cell_celltype_ok.quantile(min_score_q/100)] = True\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok != True] = False\n",
    "    if min_score == 'None':\n",
    "        scores_cell_celltype_ok = scores_cell_celltype.copy(deep=True)\n",
    "        scores_cell_celltype_ok[scores_cell_celltype_ok.round(6) == scores_cell_celltype_ok.round(6)] = True\n",
    "\n",
    "    # scale scores per cell type to make them more comparable between cell types (because some cell types have more markers etc.) \n",
    "    if scale_score == 'MinMax':\n",
    "        # if you chose this the '- mean_expression' you did before does not have an effect\n",
    "        scores_cell_celltype = scores_cell_celltype.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    if scale_score == 'ZeroMax':\n",
    "        scores_cell_celltype = scores_cell_celltype.apply(lambda x: (x) / (np.max(x))) # (~ min max scaling with min = 0)\n",
    "    #if scale_score == 'Nmarkers':\n",
    "        #Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "        #scores_cell_celltype = scores_cell_celltype.div(Nmarkers)\n",
    "    if scale_score == 'Robust':\n",
    "        for cell_type in cell_types:\n",
    "            if np.percentile(scores_cell_celltype[cell_type],scale_score_q) < np.percentile(scores_cell_celltype[cell_type],100-scale_score_q):\n",
    "                scores_cell_celltype[cell_type] = (scores_cell_celltype[cell_type] - np.percentile(scores_cell_celltype[cell_type],scale_score_q))/(np.percentile(scores_cell_celltype[cell_type],100-scale_score_q)-np.percentile(scores_cell_celltype[cell_type],scale_score_q))\n",
    "            else: # MinMax scaling if percentiles are equal \n",
    "                scores_cell_celltype[cell_type] = (scores_cell_celltype[cell_type]-np.min(scores_cell_celltype[cell_type]))/(np.max(scores_cell_celltype[cell_type])-np.min(scores_cell_celltype[cell_type]))\n",
    "    if scale_score == 'Rank':\n",
    "        for cell_type in cell_types:\n",
    "            scores_cell_celltype[cell_type] = scores_cell_celltype[cell_type].rank(pct=True)\n",
    "            \n",
    "    max_scores,second_scores=np.sort(scores_cell_celltype.values)[:,-1],np.sort(scores_cell_celltype.values)[:,-2:-1]\n",
    "    max_scores = pd.DataFrame(max_scores, index=scores_cell_celltype.index)\n",
    "    second_scores = pd.DataFrame(second_scores, index=scores_cell_celltype.index)\n",
    "    cleanliness = (max_scores - second_scores) / ((max_scores + second_scores+0.0000001) / 2)\n",
    "    scores_cell_celltype_before_min_score = scores_cell_celltype.copy(deep=True)\n",
    "    scores_cell_celltype[scores_cell_celltype_ok == False] = np.nan\n",
    "    sc_cell_cellt = scores_cell_celltype.idxmax(axis=1).to_dict()\n",
    "    unknown_cells = [k for k, v in sc_cell_cellt.items() if pd.isnull(v)]\n",
    "    for i in unknown_cells:\n",
    "        sc_cell_cellt[i] = 'Unknown'\n",
    "    sc_cell_cellt = {str(k): v for k, v in sc_cell_cellt.items()}\n",
    "    anndata.obs[\"annotation_own_score_genes\"+suffix] = sc_cell_cellt.values()\n",
    "    anndata.obs[\"score_celltype_own_score_genes\"+suffix] = max_scores.values\n",
    "    anndata.obs[\"second_score_celltype_own_score_genes\"+suffix] = second_scores.values\n",
    "    anndata.obs[\"cleanliness_own_score_genes\"+suffix] = cleanliness.values\n",
    "    anndata.uns[\"own_score_genes\"+suffix] = scores_cell_celltype_before_min_score\n",
    "    return scores_cell_celltype, scores_cell_celltype_before_min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def own_score_genes_iterative(anndata,path_mg,suffix='',nr_iterations=10,save=False,saved_as=''):\n",
    "    # initial clustering: 'mean expression' is over all cells, but will be mainly influenced by majority cell type\n",
    "    # --> disadvantage for majority cell type (Hepa), which will be countered with following iterations\n",
    "    scores = own_score_genes(anndata,path_mg,mean = 'all',scale_score='No',suffix=suffix)\n",
    "    print((anndata.obs['annotation_own_score_genes'+suffix].value_counts()/len(anndata.obs['annotation_own_score_genes'+suffix]))*100)\n",
    "    sc.pl.umap(anndata,color=['annotation_own_score_genes'+suffix])\n",
    "    anndata.obs['annotation_own_score_genes_start_iterative'+suffix] = anndata.obs['annotation_own_score_genes'+suffix]\n",
    "    anndata.uns[\"own_score_genes_start_iterative\"+suffix] = scores[0]\n",
    "    # iterative clustering: \n",
    "    # own_score_genes again but mean expression with fair contribution of each cell type (cell types are based on the previous clustering)\n",
    "    changes = []\n",
    "    completed = 0\n",
    "    for iteration in range(nr_iterations):\n",
    "        cell_types = np.unique(anndata.obs[\"annotation_own_score_genes\"+suffix]).tolist()\n",
    "        if 'Unknown' in cell_types:\n",
    "            cell_types.remove('Unknown')\n",
    "        mean_per_ct = []\n",
    "        for ct in cell_types:\n",
    "            l = pd.DataFrame(anndata.obs[\"annotation_own_score_genes\"+suffix]==ct)\n",
    "            l = l.index[l[\"annotation_own_score_genes\"+suffix]].tolist()\n",
    "            ct_sel = anndata[l,:]\n",
    "            mean_per_ct.append(ct_sel.to_df().mean(axis=0))\n",
    "        df = pd.concat(mean_per_ct,axis=1)\n",
    "        next_mean = df.mean(axis=1)\n",
    "        if 'annotation_own_score_genes_previous'+suffix in anndata.obs.columns:\n",
    "            anndata.obs.drop(columns=['annotation_own_score_genes_previous'+suffix], inplace=True)       \n",
    "        anndata.obs.rename(columns={'annotation_own_score_genes'+suffix: 'annotation_own_score_genes_previous'+suffix}, inplace=True)\n",
    "        scores = own_score_genes(anndata,path_mg,scale_score='No',suffix=suffix,mean='given',mean_values=next_mean)\n",
    "        #print(scores)\n",
    "        t = anndata.obs[\"annotation_own_score_genes\"+suffix] == anndata.obs[\"annotation_own_score_genes_previous\"+suffix]\n",
    "        anndata.obs[\"own_score_genes_diff_iter\"+suffix] = [int(x) for x in t.to_list()]\n",
    "        fr = anndata.obs['own_score_genes_diff_iter'+suffix].value_counts()/len(anndata.obs['own_score_genes_diff_iter'+suffix])        \n",
    "        completed = completed + 1\n",
    "        if len(fr) > 1 and (fr[0]*100) > 0.05:\n",
    "            print('Percentage of cells with changed annotation: '+str(np.round((fr[0]*100),2)))\n",
    "            changes.append(fr[0]*100)\n",
    "            sc.pl.umap(anndata,color=['own_score_genes_diff_iter'+suffix])\n",
    "            sc.pl.umap(anndata,color=['annotation_own_score_genes'+suffix])\n",
    "            print((anndata.obs['annotation_own_score_genes'+suffix].value_counts()/len(anndata.obs['annotation_own_score_genes'+suffix]))*100)\n",
    "        else:\n",
    "            if len(fr) > 1:\n",
    "                print('Percentage of cells with changed annotation: '+str(np.round((fr[0]*100),2)))\n",
    "            else:\n",
    "                print('Percentage of cells with changed annotation: '+str(0.0))\n",
    "            print('converged')\n",
    "            changes.append(0)\n",
    "            break\n",
    "    plt.plot(list(range(1,completed+1,1)),changes)    \n",
    "    # make x-axis integers and start from 1\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Percentage of cells with changed annotation')\n",
    "    # save plot in folder output dir\n",
    "    if save:\n",
    "        plt.savefig(saved_as+'.png',dpi=300)\n",
    "    # drop columns from anndata.obs\n",
    "    anndata.obs.drop(columns=['own_score_genes_diff_iter'+suffix], inplace=True)\n",
    "    anndata.obs.drop(columns=['annotation_own_score_genes_previous'+suffix], inplace=True)\n",
    "    return scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_umap_and_perform_leiden_annotation(sdata,path_mg,n_PCAs,n_neighbors,cluster_resolution,norm_expr_var=True,min_score='Quantile',min_score_q=25,scale_score='Robust',scale_score_q=1,clean_th=0.5)->pd.DataFrame:\n",
    "\n",
    "    # make umap and do leiden clustering with scanpy functions\n",
    "    make_umap(sdata,n_neighbors=n_neighbors,n_PCAs=n_PCAs)\n",
    "    column_name = 'leiden_'+str(n_PCAs)+'_'+str(n_neighbors)+'_'+str(cluster_resolution)\n",
    "    sc.tl.leiden(sdata.table,resolution=cluster_resolution,key_added=column_name)\n",
    "\n",
    "    # annotate each leiden cluster\n",
    "    # method based on marker genes and similar to 'own_score_genes' but leiden clusters annotated instead of individual cells\n",
    "    # for each leiden cluster, a score is calculated for each cell type: \n",
    "    # sum of the mean expressions of the markers in leiden cluster - sum of mean expression of the markers in all cells\n",
    "    n_clusters = np.unique(sdata.table.obs[column_name]).size\n",
    "    leiden_mean_expression = {}\n",
    "    for i in range(n_clusters):\n",
    "        an_cluster = sdata.table[sdata.table.obs[column_name]==str(i)]\n",
    "        daf = an_cluster.to_df().mean(axis=0)\n",
    "        pd.DataFrame(daf)\n",
    "        leiden_mean_expression[i] = daf\n",
    "    if norm_expr_var:\n",
    "        matrix = sdata.table.to_df()\n",
    "        all_mean_expression = matrix.div(matrix.std(axis=0)).mean(axis=0)\n",
    "        for i in range(n_clusters):\n",
    "            leiden_mean_expression[i] = leiden_mean_expression[i].div(matrix.std(axis=0))\n",
    "    else:\n",
    "        all_mean_expression = sdata.table.to_df().mean(axis=0)\n",
    "    path_marker_genes = path_mg,\n",
    "    marker_genes = pd.read_csv(path_marker_genes[0], sep=',',index_col=0)\n",
    "    scores_leiden_celltype = pd.DataFrame()\n",
    "    cell_types = marker_genes.columns.tolist()\n",
    "    for cell_type in cell_types:\n",
    "        scores_clusters = []\n",
    "        for i in range(n_clusters):\n",
    "            score = 0 \n",
    "            for gene in marker_genes[marker_genes[cell_type] == 1].index.tolist():\n",
    "                score = score + (leiden_mean_expression[i][gene] - all_mean_expression[gene])\n",
    "            scores_clusters.append(score)\n",
    "        scores_leiden_celltype[cell_type] = scores_clusters\n",
    "    \n",
    "    # min score to obtain for a cell type, otherwise 'unknown' \n",
    "    if min_score == 'Zero':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok > 0] = True\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok != True] = False\n",
    "    if min_score == 'Quantile':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok > scores_leiden_celltype_ok.quantile(min_score_q/100)] = True\n",
    "        print(min_score_q/100)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok != True] = False\n",
    "    if min_score == 'None':\n",
    "        scores_leiden_celltype_ok = scores_leiden_celltype.copy(deep=True)\n",
    "        scores_leiden_celltype_ok[scores_leiden_celltype_ok.round(6) == scores_leiden_celltype_ok.round(6)] = True\n",
    "\n",
    "    # scale scores per cell type to make them more comparable between cell types (because some cell types have more markers etc.) \n",
    "    if scale_score == 'MinMax':\n",
    "        scores_leiden_celltype = scores_leiden_celltype.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    if scale_score == 'ZeroMax':\n",
    "        scores_leiden_celltype = scores_leiden_celltype.apply(lambda x: (x) / (np.max(x))) # (~ min max scaling with min = 0)\n",
    "    if scale_score == 'Nmarkers':\n",
    "        Nmarkers = marker_genes.sum(axis=0).to_list()\n",
    "        scores_leiden_celltype = scores_leiden_celltype.div(Nmarkers)\n",
    "    if scale_score == 'Robust':\n",
    "        for cell_type in cell_types:\n",
    "            if np.percentile(scores_leiden_celltype[cell_type],scale_score_q) < np.percentile(scores_leiden_celltype[cell_type],100-scale_score_q):\n",
    "                scores_leiden_celltype[cell_type] = (scores_leiden_celltype[cell_type] - np.percentile(scores_leiden_celltype[cell_type],scale_score_q))/(np.percentile(scores_leiden_celltype[cell_type],100-scale_score_q)-np.percentile(scores_leiden_celltype[cell_type],scale_score_q))\n",
    "            else: # MinMax scaling if percentiles are equal \n",
    "                scores_leiden_celltype[cell_type] = (scores_leiden_celltype[cell_type]-np.min(scores_leiden_celltype[cell_type]))/(np.max(scores_leiden_celltype[cell_type])-np.min(scores_leiden_celltype[cell_type]))\n",
    "    if scale_score == 'Rank':\n",
    "        for cell_type in cell_types:\n",
    "            scores_leiden_celltype[cell_type] = scores_leiden_celltype[cell_type].rank(pct=True)\n",
    "\n",
    "    # cluster is annotated with the cell type with the highest score (+ this highest score is above min_score)\n",
    "    scores_leiden_celltype[scores_leiden_celltype_ok == False] = np.nan\n",
    "    sc_leiden_cellt = scores_leiden_celltype.idxmax(axis=1).to_dict()\n",
    "    unknown_clusters = [k for k, v in sc_leiden_cellt.items() if pd.isnull(v)]\n",
    "\n",
    "    max_scores = scores_leiden_celltype.max(axis=1)\n",
    "    second_scores = scores_leiden_celltype.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
    "    cleanl_per_cluster = (max_scores - second_scores) / ((max_scores + second_scores) / 2)\n",
    "    third_scores = scores_leiden_celltype.apply(lambda x: x.nlargest(3).values[-1], axis=1)\n",
    "    cleanl_per_cluster_extra = (max_scores - third_scores) / ((max_scores + third_scores) / 2)\n",
    "    scores_draft = scores_leiden_celltype.copy(deep=True)\n",
    "    for i in range(n_clusters):\n",
    "        if cleanl_per_cluster[i] < clean_th:\n",
    "            scores_draft.loc[i].at[scores_draft.idxmax(axis=1)[i]] = np.nan \n",
    "            sc_leiden_cellt[i] = sc_leiden_cellt[i] + '/' + scores_draft.idxmax(axis=1)[i]\n",
    "            if cleanl_per_cluster_extra[i] < clean_th:\n",
    "                scores_draft.loc[i].at[scores_draft.idxmax(axis=1)[i]] = np.nan \n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '/' + scores_draft.idxmax(axis=1)[i]\n",
    "                sum = abs(max_scores[i] + second_scores[i] + third_scores[i])\n",
    "                if max_scores[i] > 0:\n",
    "                    p1 = round(100*max_scores[i]/sum)\n",
    "                    p2 = round(100*second_scores[i]/sum)\n",
    "                    p3 = round(100*third_scores[i]/sum)\n",
    "                else:\n",
    "                    p1 = round(100*(sum + max_scores[i])/(2*sum))\n",
    "                    p2 = round(100*(sum + second_scores[i])/(2*sum))\n",
    "                    p3 = round(100*(sum + third_scores[i])/(2*sum))\n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '(' + str(p1) + '%/' + str(p2) + '%/' + str(p3) + '%)'\n",
    "            else:\n",
    "                sum = abs(max_scores[i] + second_scores[i])\n",
    "                if max_scores[i] > 0:\n",
    "                    p1 = round(100*max_scores[i]/sum)\n",
    "                    p2 = round(100*second_scores[i]/sum)\n",
    "                else:\n",
    "                    p1 = round(100*(sum + max_scores[i])/sum)\n",
    "                    p2 = round(100*(sum + second_scores[i])/sum)\n",
    "                sc_leiden_cellt[i] = sc_leiden_cellt[i] + '(' + str(p1) + '%/' + str(p2) + '%)'\n",
    "    # change the values of keys in list\n",
    "    for i in unknown_clusters:\n",
    "        sc_leiden_cellt[i] = 'Unknown'\n",
    "    sc_leiden_cellt = {str(k): v for k, v in sc_leiden_cellt.items()}\n",
    "    sdata.table.obs[\"annotation_\"+column_name]=sdata.table.obs[column_name] \n",
    "    sdata.table.obs[\"annotation_\"+column_name].replace(list(sc_leiden_cellt.keys()),list(sc_leiden_cellt.values()), inplace=True)\n",
    "    b = pd.DataFrame.from_dict(sc_leiden_cellt, orient='index')\n",
    "    cell_type_leiden = {}\n",
    "    cell_types = np.unique(b[0])\n",
    "    for cell_type in cell_types:\n",
    "        indices = b.index[b[0] == cell_type].tolist()\n",
    "        cell_type_leiden[cell_type] = indices\n",
    "    sdata.table.uns[\"mapping_cell_type_\"+column_name] = cell_type_leiden\n",
    "    # cleanliness of the annotation based on highest and second highest score\n",
    "    sc_leiden_cleanl = cleanl_per_cluster.to_dict()\n",
    "    for i in unknown_clusters:\n",
    "        sc_leiden_cleanl[i] = 0\n",
    "    sc_leiden_cleanl = {str(k): v for k, v in sc_leiden_cleanl.items()}\n",
    "    sdata.table.obs[\"cleanliness_\"+column_name]=sdata.table.obs[column_name] \n",
    "    sdata.table.obs[\"cleanliness_\"+column_name].replace(list(sc_leiden_cleanl.keys()),list(sc_leiden_cleanl.values()), inplace=True)\n",
    "\n",
    "    return scores_leiden_celltype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model,N_clusters,labels) -> dict:\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    R = dendrogram(linkage_matrix,truncate_mode='lastp',p=N_clusters,no_plot=True)   \n",
    "    \n",
    "    R2 = dendrogram(linkage_matrix,labels=labels,no_plot=True)  \n",
    "    clusters = np.array(list(dict.fromkeys(R2[\"ivl\"])))\n",
    "    clusters = clusters.astype(str)\n",
    "\n",
    "    # create a label dictionary\n",
    "    temp = {R[\"leaves\"][ii]: clusters[ii] + ' ' + R[\"ivl\"][ii] for ii in range(len(R[\"leaves\"]))}\n",
    "    def llf(xx):\n",
    "        return \"{}\".format(temp[xx])\n",
    "\n",
    "    dendrogram(linkage_matrix,leaf_label_func=llf,leaf_rotation=60.,leaf_font_size=10.,truncate_mode='lastp',p=N_clusters)\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_clustering(sdata,matrix_score_genes,N_clusters,suffix_name=''):\n",
    "    kmeans = KMeans(n_clusters = N_clusters, n_init=10) # run 10 times with different centroid seeds\n",
    "    kmeans_annotation = kmeans.fit_predict(matrix_score_genes)\n",
    "    kmeans_annotation = kmeans_annotation.astype(str)\n",
    "    sdata.table.obs[\"KMeans\"+str(N_clusters)+suffix_name] = kmeans_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hierarchical_clustering(sdata,matrix_score_genes,N_clusters,suffix_name='',levels_dendrogram=4)-> dict:\n",
    "    hier = AgglomerativeClustering(n_clusters=N_clusters,compute_distances=True)\n",
    "    hierarchical = hier.fit(matrix_score_genes)\n",
    "    hierarchical_annotation = hierarchical.fit_predict(matrix_score_genes)\n",
    "    hierarchical_annotation = hierarchical_annotation.astype(str)\n",
    "    sdata.table.obs[\"Hierarchical\"+str(N_clusters)+suffix_name] = hierarchical_annotation\n",
    "    R = plot_dendrogram(hierarchical,N_clusters=N_clusters,labels=hierarchical_annotation)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix_expression_marker_genes_of_2_cell_types(anndata,path_mg,type1,type2):\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    gene_set1 = df_mg.index[df_mg[type1]>0].tolist()\n",
    "    gene_set2 = df_mg.index[df_mg[type2]>0].tolist()\n",
    "    df_genes = pd.DataFrame()\n",
    "    overlap = [g for g in gene_set1 if g in gene_set2]\n",
    "    gene_set1 = [g for g in gene_set1 if g not in overlap]\n",
    "    gene_set2 = [g for g in gene_set2 if g not in overlap]\n",
    "    for g in gene_set1:\n",
    "        df_genes[g+' '+type1] = anndata.to_df()[g]\n",
    "    for g in overlap:\n",
    "        df_genes[g+' both'] = anndata.to_df()[g]\n",
    "    for g in gene_set2:\n",
    "        df_genes[g+' '+type2] = anndata.to_df()[g]\n",
    "    sns.heatmap(df_genes.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEGs_between_2_sets_leiden_clusters_compared_to_markers(adata,name_cell_type1, putative_leiden_clusters_cell_type1, name_cell_type2, putative_leiden_clusters_cell_type2, path_mg)->dict:\n",
    "    leidcl1 = [str(x[0]) for x in putative_leiden_clusters_cell_type1]\n",
    "    leidcl2 = [str(x[0]) for x in putative_leiden_clusters_cell_type2]\n",
    "    a = adata.obs['leiden']\n",
    "    for n in leidcl1:\n",
    "        a = a.replace(n,leidcl1[0])\n",
    "    for n in leidcl2:\n",
    "        a = a.replace(n,leidcl2[0])\n",
    "    adata.obs['leiden_mod'] = a\n",
    "    #adata.uns['log1p'][\"base\"] = None\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', groups = [leidcl1[0],leidcl2[0]], method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes=99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    genes.rename(columns = {leidcl1[0]:'gene_'+name_cell_type1,leidcl2[0]:'gene_'+name_cell_type2},inplace=True)\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    pvals_adj.rename(columns = {leidcl1[0]:'pval_adj_'+name_cell_type1,leidcl2[0]:'pval_adj_'+name_cell_type2},inplace=True)\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    logf2.rename(columns = {leidcl1[0]:'logf2_'+name_cell_type1,leidcl2[0]:'logf2_'+name_cell_type2},inplace=True)\n",
    "    df = pd.concat([genes,pvals_adj,logf2],axis=1)\n",
    "    df_ct1_vs_rest = df[['gene_'+name_cell_type1,'pval_adj_'+name_cell_type1,'logf2_'+name_cell_type1]]\n",
    "    df_ct1_vs_rest = df_ct1_vs_rest[(df_ct1_vs_rest['pval_adj_'+name_cell_type1] < 0.01) & (df_ct1_vs_rest['logf2_'+name_cell_type1] > 0)]\n",
    "    df_ct2_vs_rest = df[['gene_'+name_cell_type2,'pval_adj_'+name_cell_type2,'logf2_'+name_cell_type2]]\n",
    "    df_ct2_vs_rest = df_ct2_vs_rest[(df_ct2_vs_rest['pval_adj_'+name_cell_type2] < 0.01) & (df_ct2_vs_rest['logf2_'+name_cell_type2] > 0)]\n",
    "\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', groups = [leidcl1[0]], reference = leidcl2[0], method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes = 99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    genes.rename(columns = {leidcl1[0]:'gene'},inplace=True)\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    pvals_adj.rename(columns = {leidcl1[0]:'pval_adj'},inplace=True)\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    logf2.rename(columns = {leidcl1[0]:'logf2'},inplace=True)\n",
    "    df_ct1_vs_ct2 = pd.concat([genes,pvals_adj,logf2],axis=1)\n",
    "    df_ct1_vs_ct2 = df_ct1_vs_ct2[df_ct1_vs_ct2['pval_adj'] < 0.01]\n",
    "    \n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    mg_ct1 = df_mg.index[df_mg[name_cell_type1]>0].tolist()\n",
    "    mg_ct2 = df_mg.index[df_mg[name_cell_type2]>0].tolist()\n",
    "    mg_overlap = [x for x in mg_ct1 if x in mg_ct2]\n",
    "    df_overlap = df_ct1_vs_ct2[df_ct1_vs_ct2['gene'].isin(mg_overlap)]\n",
    "    candidates_ct1 = df_overlap[df_overlap['logf2']>0]['gene'].to_list()\n",
    "    candidates_ct2 = df_overlap[df_overlap['logf2']<0]['gene'].to_list()\n",
    "    drop_ct2 = []\n",
    "    if len(candidates_ct1)>0:\n",
    "        reject1 = df_ct2_vs_rest[df_ct2_vs_rest['gene_'+name_cell_type2].isin(candidates_ct1)]['gene_'+name_cell_type2].to_list()\n",
    "        drop_ct2 = [x for x in candidates_ct1 if x not in reject1]    \n",
    "    drop_ct1 = []\n",
    "    if len(candidates_ct2)>0:\n",
    "        reject2 = df_ct1_vs_rest[df_ct1_vs_rest['gene_'+name_cell_type1].isin(candidates_ct2)]['gene_'+name_cell_type1].to_list()\n",
    "        drop_ct1 = [x for x in candidates_ct2 if x not in reject2]\n",
    "    results = {'DEGs': df_ct1_vs_ct2, 'DEGs_'+name_cell_type1+'_vs_rest': df_ct1_vs_rest, 'DEGs_'+name_cell_type2+'_vs_rest': df_ct2_vs_rest, 'markers_'+name_cell_type1: mg_ct1, 'markers_'+name_cell_type2: mg_ct2, 'overlap_markers': mg_overlap, 'drop_'+name_cell_type1: drop_ct1, 'drop_'+name_cell_type2: drop_ct2}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DEGs_between_each_leiden_cluster_and_rest_compared_to_markers(adata,name_cell_types, putative_leiden_clusters_per_cell_type, path_mg)->dict:\n",
    "    a = adata.obs['leiden']\n",
    "    leidcl = []\n",
    "    for putative_leiden_clusters in putative_leiden_clusters_per_cell_type:\n",
    "        L = [str(x[0]) for x in putative_leiden_clusters]\n",
    "        for n in L:\n",
    "            a = a.replace(n,L[0])\n",
    "        leidcl.append(L[0])\n",
    "    adata.obs['leiden_mod'] = a\n",
    "    print(leidcl)\n",
    "    #adata.uns['log1p'][\"base\"] = None\n",
    "    sc.tl.rank_genes_groups(adata, groupby='leiden_mod', method = 'wilcoxon')\n",
    "    #sc.pl.rank_genes_groups(sdata.table, n_genes=99, sharey=False, show=False)\n",
    "    genes = pd.DataFrame(adata.uns['rank_genes_groups']['names'])\n",
    "    pvals_adj = pd.DataFrame(adata.uns['rank_genes_groups']['pvals_adj'])\n",
    "    logf2 = pd.DataFrame(adata.uns['rank_genes_groups']['logfoldchanges'])\n",
    "    dict_df_ct_vs_rest = {}\n",
    "    dict_ct_markers = {}\n",
    "    dict_ct_pos_DEG_but_not_marker = {}\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    i = 0\n",
    "    for nr in leidcl:\n",
    "        df_ct_vs_rest = pd.concat([genes[[nr]],pvals_adj[[nr]],logf2[[nr]]],axis=1)\n",
    "        # change column names of df_ct_vs_rest\n",
    "        df_ct_vs_rest.columns = ['gene','pvals_adj','logf2']\n",
    "        df_ct_vs_rest = df_ct_vs_rest[df_ct_vs_rest['pvals_adj'] < 0.01]\n",
    "        dict_df_ct_vs_rest[name_cell_types[i]] = df_ct_vs_rest\n",
    "        if name_cell_types[i] != 'Unknown':\n",
    "            markers_ct = df_mg.index[df_mg[name_cell_types[i]]>0].tolist()\n",
    "        else:\n",
    "            markers_ct = []\n",
    "        dict_ct_markers[name_cell_types[i]] = markers_ct\n",
    "        pos_DEGs_but_no_mg = df_ct_vs_rest[(~df_ct_vs_rest['gene'].isin(markers_ct)) & (df_ct_vs_rest['logf2'] > 0)]\n",
    "        dict_ct_pos_DEG_but_not_marker[name_cell_types[i]] = pos_DEGs_but_no_mg\n",
    "        i = i + 1\n",
    "   \n",
    "    results = {'DEGs': dict_df_ct_vs_rest, 'markers': dict_ct_markers, 'pos_DEGs_but_not_marker': dict_ct_pos_DEG_but_not_marker}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(list1,list2):\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] > 0:\n",
    "            list1[i] = 1\n",
    "    for i in range(len(list2)):\n",
    "        if list2[i] > 0:\n",
    "            list2[i] = 1\n",
    "    list3 = [list1[i] and list2[i] for i in range(len(list1))]\n",
    "    list4 = [list1[i] or list2[i] for i in range(len(list1))]\n",
    "    Jaccard = np.sum(list3)/np.sum(list4)    \n",
    "    return np.round(Jaccard,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_similarity_matrix(path_mg,name):\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    Jaccard_sim = pd.DataFrame(index=df_mg.columns, columns=df_mg.columns)\n",
    "    for i in df_mg.columns:\n",
    "        for j in df_mg.columns:\n",
    "            Jaccard_sim.loc[i,j] = Jaccard(df_mg[i].to_list(),df_mg[j].to_list())\n",
    "    Jaccard_sim = Jaccard_sim.astype(float)\n",
    "    sns.heatmap(Jaccard_sim,annot=True,fmt='.2f')\n",
    "    plt.title('Jaccard similarity matrix '+name)\n",
    "    print(df_mg.sum(axis=0))\n",
    "    return Jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_1(adata,cell_types,leiden_clusters,path_mg)->dict:\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    n_ct = len(cell_types)\n",
    "    marker_gene_drop = {}\n",
    "    details_DEGs = {}\n",
    "    for i in range(n_ct):\n",
    "        for j in range(i+1,n_ct):            \n",
    "            d = DEGs_between_2_sets_leiden_clusters_compared_to_markers(adata,cell_types[i],leiden_clusters[i],cell_types[j],leiden_clusters[j],path_mg)\n",
    "            details_DEGs[cell_types[i]+'_'+cell_types[j]] = d\n",
    "            if len(d['drop_'+cell_types[i]])>0:\n",
    "                for g in d['drop_'+cell_types[i]]:\n",
    "                    if df_mg.loc[g,cell_types[i]] >= df_mg.loc[g,cell_types[j]]:\n",
    "                        if cell_types[i] in marker_gene_drop:\n",
    "                            marker_gene_drop[cell_types[i]].append([g,cell_types[j]])\n",
    "                        else:\n",
    "                            marker_gene_drop[cell_types[i]] = []\n",
    "                            marker_gene_drop[cell_types[i]].append([g,cell_types[j]])\n",
    "            if len(d['drop_'+cell_types[j]])>0:\n",
    "                for g in d['drop_'+cell_types[j]]:\n",
    "                    if df_mg.loc[g,cell_types[j]] >= df_mg.loc[g,cell_types[i]]:\n",
    "                        if cell_types[j] in marker_gene_drop:\n",
    "                            marker_gene_drop[cell_types[j]].append([g,cell_types[i]])\n",
    "                        else:\n",
    "                            marker_gene_drop[cell_types[j]] = []\n",
    "                            marker_gene_drop[cell_types[j]].append([g,cell_types[i]])\n",
    "    print('Summary:')\n",
    "    for key in marker_gene_drop.keys():\n",
    "        print(key)\n",
    "        print('Maybe drop:'+str(marker_gene_drop[key]))\n",
    "    return marker_gene_drop, details_DEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_2(adata,cell_types,leiden_clusters,path_mg)->(dict,dict):\n",
    "    dict_DEGs = DEGs_between_each_leiden_cluster_and_rest_compared_to_markers(adata,cell_types,leiden_clusters,path_mg)\n",
    "    df_mg = pd.read_csv(path_mg,index_col=0)\n",
    "    genes = adata.var_names\n",
    "    marker_genes = df_mg.index.tolist()\n",
    "    marker_gene_add = {}\n",
    "    for gene in genes:\n",
    "        candidates = []\n",
    "        for i in cell_types:\n",
    "            if gene in dict_DEGs['pos_DEGs_but_not_marker'][i]['gene'].tolist():\n",
    "                candidates.append(i)\n",
    "                if i in marker_gene_add:\n",
    "                    marker_gene_add[i].append(gene)\n",
    "                else:\n",
    "                    marker_gene_add[i] = [gene]\n",
    "        if(len(candidates) > 0):\n",
    "            print(gene)\n",
    "            if gene in marker_genes:\n",
    "                a = df_mg.loc[gene,:]\n",
    "                b = a[a>0].index.values\n",
    "                print('Is marker gene of: '+str(b.tolist()))\n",
    "                print('Could also be a marker gene of: '+str(candidates))\n",
    "            else:\n",
    "                print('Is marker gene of: []')\n",
    "                print('Could also be a marker gene of: '+str(candidates))\n",
    "    print('Summary:')\n",
    "    for key in marker_gene_add.keys():\n",
    "        print(key)\n",
    "        print('Maybe add:'+str(marker_gene_add[key]))\n",
    "    return marker_gene_add, dict_DEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apply_strategy_multiple_times(adata,annotation,path_mg,N,strategy,output_dir):\n",
    "    results_runs = {}\n",
    "    DEG_details_runs = {}\n",
    "    Not_considered_celltypes = []\n",
    "    Not_considered_leiden_clusters = []\n",
    "\n",
    "    cell_types = adata.obs[annotation].unique().tolist()  \n",
    "    leiden_clusters = clusteringVSleiden(adata,annotation,\"leiden\",cell_types=cell_types,print_results=False)\n",
    "\n",
    "    nr_cells_of_each_cons_ct = []\n",
    "    for i in range(len(cell_types)):\n",
    "        if len(leiden_clusters[i])>0 and cell_types[i] != 'Unknown':\n",
    "            leiden_cl = [str(x[0]) for x in leiden_clusters[i]]\n",
    "            leiden = adata[(adata.obs['leiden'].isin(leiden_cl))&(adata.obs[annotation]==cell_types[i]),:]\n",
    "            nr_cells_of_each_cons_ct.append(len(leiden))\n",
    "\n",
    "    n_cells = min(nr_cells_of_each_cons_ct)\n",
    "\n",
    "    print(\"\"+str(n_cells)+\" cells randomly sampled from each cell type in every iteration to do the DEG analysis\")\n",
    "\n",
    "    for k in range(N):\n",
    "        list_sub_anndata = []\n",
    "        for i in range(len(cell_types)):\n",
    "            if len(leiden_clusters[i])>0 and cell_types[i] != 'Unknown':\n",
    "                leiden_cl = [str(x[0]) for x in leiden_clusters[i]]\n",
    "                leiden = adata[(adata.obs['leiden'].isin(leiden_cl))&(adata.obs[annotation]==cell_types[i]),:]\n",
    "                leiden_cells = leiden.obs.index.to_list()\n",
    "                leiden_cells_random = sample(leiden_cells,n_cells)\n",
    "                leiden = leiden[leiden_cells_random,:]\n",
    "                list_sub_anndata.append(leiden)\n",
    "            else:\n",
    "                Not_considered_celltypes.append(cell_types[i])\n",
    "                if leiden_clusters[i] not in Not_considered_leiden_clusters:\n",
    "                    Not_considered_leiden_clusters.append(leiden_clusters[i])\n",
    "        cell_types = [x for x in cell_types if x not in Not_considered_celltypes]\n",
    "        leiden_clusters = [x for x in leiden_clusters if x not in Not_considered_leiden_clusters]\n",
    "        sub_anndata = ad.concat(list_sub_anndata)\n",
    "        if strategy == 1:\n",
    "            results_runs[k],DEG_details_runs[k] = Apply_strategy_1(sub_anndata,cell_types,leiden_clusters,path_mg)\n",
    "        if strategy == 2:\n",
    "            results_runs[k],DEG_details_runs[k] = Apply_strategy_2(sub_anndata,cell_types,leiden_clusters,path_mg)\n",
    "\n",
    "    counts_run = {}\n",
    "    for key in results_runs.keys():\n",
    "        for k in results_runs[key].keys():\n",
    "            if k not in counts_run.keys():\n",
    "                counts_run[k] = results_runs[key][k]\n",
    "            else:\n",
    "                for i in results_runs[key][k]:\n",
    "                    counts_run[k].append(i)\n",
    "    final = {}\n",
    "    for key in counts_run:\n",
    "        df = pd.DataFrame(counts_run[key]).value_counts()\n",
    "        # keep rows with value > N/2\n",
    "        print(df)\n",
    "        df = df[df > N/2]\n",
    "        final[key] = df.index.to_list()\n",
    "\n",
    "    colors = []\n",
    "    for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "    for c in plt.cm.tab20b.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "\n",
    "    if strategy == 1:\n",
    "        sign_tuples = []\n",
    "        for key in final.keys():\n",
    "            for t in final[key]:\n",
    "                sign_tuples.append((key,t))\n",
    "        sign_tuples = [(x[0],x[1][0],x[1][1]) for x in sign_tuples]\n",
    "\n",
    "        DEGs_runs = {} \n",
    "        DEGs_runs_sign = {}\n",
    "        n_ct = len(cell_types)\n",
    "        for r in range(N):\n",
    "            dfs = []\n",
    "            for i in range(n_ct):\n",
    "                for j in range(i+1,n_ct):\n",
    "                    if cell_types[i] != 'Unknown' and cell_types[j] != 'Unknown':\n",
    "                        df = DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['DEGs']\n",
    "                        df['ct1'] = cell_types[i]\n",
    "                        df['ct2'] = cell_types[j]\n",
    "                        # only keep rows with value of gene in overlap_markers\n",
    "                        df = df[df['gene'].isin(DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['overlap_markers'])]\n",
    "                        # only keep rows if gene is not sign expressed vs the rest in cell type with smaller expression (see def strategy 1)\n",
    "                        ct1_sign_vs_rest = DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['DEGs_'+cell_types[i]+'_vs_rest']['gene_'+cell_types[i]].to_list()\n",
    "                        ct2_sign_vs_rest = DEG_details_runs[r][cell_types[i]+'_'+cell_types[j]]['DEGs_'+cell_types[j]+'_vs_rest']['gene_'+cell_types[j]].to_list()\n",
    "                        genes = df['gene'].to_list()\n",
    "                        for g in genes:\n",
    "                            # get logf2 of row in df with gene equal to g\n",
    "                            logf2 = df[df['gene']==g]['logf2'].to_list()[0]\n",
    "                            if logf2 > 0:\n",
    "                                if g in ct2_sign_vs_rest:\n",
    "                                    df = df[df['gene'] != g]\n",
    "                            else:\n",
    "                                if g in ct1_sign_vs_rest:\n",
    "                                    df = df[df['gene'] != g]\n",
    "                        dfs.append(df)                 \n",
    "            DEGs_runs[r] = pd.concat(dfs)\n",
    "            \n",
    "            s = []\n",
    "            s.append(DEGs_runs[r].merge(pd.DataFrame(sign_tuples, columns=['ct1','gene','ct2'])))\n",
    "            s.append(DEGs_runs[r].merge(pd.DataFrame(sign_tuples, columns=['ct2','gene','ct1'])))\n",
    "            DEGs_runs_sign[r] = pd.concat(s)\n",
    "\n",
    "        all_together = []\n",
    "        for r in range(N):\n",
    "            all_together.append(DEGs_runs[r])\n",
    "        df_all_together = pd.concat(all_together)\n",
    "\n",
    "        all_together_sign = []\n",
    "        all_together_sign.append(df_all_together.merge(pd.DataFrame(sign_tuples, columns=['ct1','gene','ct2'])))\n",
    "        all_together_sign.append(df_all_together.merge(pd.DataFrame(sign_tuples, columns=['ct2','gene','ct1'])))\n",
    "        df_all_together_sign = pd.concat(all_together_sign)\n",
    "\n",
    "        logpadj_min_plot = df_all_together['pval_adj'].min()/10\n",
    "        logpadj_max_plot = 0.5\n",
    "        logf2_max_plot = df_all_together['logf2'].max() + 0.2\n",
    "        logf2_min_plot = df_all_together['logf2'].min() - 0.2\n",
    "\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in DEGs_runs.keys():\n",
    "            ax.scatter(DEGs_runs[run]['pval_adj'].to_list(),DEGs_runs[run]['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in DEGs_runs_sign.keys():\n",
    "            ax.scatter(DEGs_runs_sign[run]['pval_adj'].to_list(),DEGs_runs_sign[run]['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "        #ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        #ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for i in range(n_ct):\n",
    "                for j in range(n_ct):\n",
    "                    df = df_all_together[df_all_together['ct1'] == cell_types[i]]\n",
    "                    df = df[df['ct2'] == cell_types[j]]\n",
    "                    if len(df) > 0:\n",
    "                        ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=cell_types[i]+'/'+cell_types[j],c=colors[c])\n",
    "                        c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for i in range(n_ct):\n",
    "                for j in range(n_ct):\n",
    "                    df = df_all_together_sign[df_all_together_sign['ct1'] == cell_types[i]]\n",
    "                    df = df[df['ct2'] == cell_types[j]]\n",
    "                    if(len(df) > 0):\n",
    "                        ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=cell_types[i]+'/'+cell_types[j],c=colors[c])\n",
    "                        c = (c + 1)%40\n",
    "        ax.legend()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "        #ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        #ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_1')\n",
    "        plt.show()\n",
    "\n",
    "        genes_all = df_all_together['gene'].unique()\n",
    "        genes_all_sets = []\n",
    "        for i in range(0,len(genes_all),10):\n",
    "                    genes_all_sets.append(genes_all[i:i+10])\n",
    "                \n",
    "        for genes in genes_all_sets:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for i in range(n_ct):\n",
    "                for j in range(i+1,n_ct):            \n",
    "                    for g in genes:\n",
    "                        df = df_all_together[df_all_together['ct1'] == cell_types[i]]\n",
    "                        df = df[df['ct2'] == cell_types[j]]\n",
    "                        df = df[df['gene'] == g]\n",
    "                        if len(df) > 0:\n",
    "                            ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=g + ' ('+cell_types[i]+'/'+cell_types[j]+')',c=colors[c])\n",
    "                            c = (c + 1)%40\n",
    "            ax.legend()\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "            ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "            ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_found_strategy_1')\n",
    "            plt.show()\n",
    "\n",
    "        genes_all_sign = df_all_together_sign['gene'].unique()\n",
    "        genes_all_sets_sign = []\n",
    "        for i in range(0,len(genes_all_sign),20):\n",
    "                    genes_all_sets_sign.append(genes_all_sign[i:i+20])\n",
    "                \n",
    "        # create file to write output to\n",
    "        g1 = open(output_dir+'/DEGs_kept_strategy_1_all_info.txt', 'w+')\n",
    "        for genes in genes_all_sets_sign:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for i in range(n_ct):\n",
    "                for j in range(i+1,n_ct):            \n",
    "                    for g in genes:\n",
    "                        df = df_all_together_sign[df_all_together_sign['ct1'] == cell_types[i]]\n",
    "                        df = df[df['ct2'] == cell_types[j]]\n",
    "                        df = df[df['gene'] == g]\n",
    "                        if len(df) > 0:\n",
    "                            ax.scatter(df['pval_adj'].to_list(),df['logf2'].to_list(), label=g + ' ('+cell_types[i]+'/'+cell_types[j]+')',c=colors[c])\n",
    "                            c = (c + 1)%40\n",
    "                            # write output to file separated by tabs\n",
    "                            if np.average(df['logf2'].to_list()) > 0:\n",
    "                                g1.write(g + ' ' + cell_types[i]+'/'+ cell_types[j] + ' ' + str(df['logf2'].to_list()) + ' ' + str(df['pval_adj'].to_list()) + ' <->markers: ' + cell_types[i] + ' ' + '<=' + ' ' + cell_types[j] + '\\n')\n",
    "                            else:\n",
    "                                g1.write(g + ' ' + cell_types[i]+'/'+ cell_types[j] + ' ' + str(df['logf2'].to_list()) + ' ' + str(df['pval_adj'].to_list()) + ' <->markers: ' + cell_types[i] + ' ' + '>=' + ' ' + cell_types[j] + '\\n')\n",
    "            ax.legend()\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "            #ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "            #ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_kept_strategy_1')\n",
    "            plt.show()\n",
    "        g1.close()\n",
    "        \n",
    "        genes_drop = []\n",
    "        for keys in final.keys():\n",
    "            for g in final[keys]:\n",
    "                if g[0] not in genes_drop:\n",
    "                    genes_drop.append(g[0])\n",
    "        sc.pl.heatmap(adata,var_names=genes_drop,groupby=annotation,standard_scale='var',show_gene_labels=True,save='_strategy_1_genes.png')\n",
    "        adata_sub = adata[~(adata.obs[annotation]=='Hepa'),:]\n",
    "        sc.pl.heatmap(adata_sub,var_names=genes_drop,groupby=annotation,standard_scale='var',show_gene_labels=True,save='_strategy_1_genes_noHepa.png')\n",
    "\n",
    "    if strategy == 2:\n",
    "        for key in final.keys():\n",
    "            final[key] = [i[0] for i in final[key]]\n",
    "\n",
    "        sign_tuples = []\n",
    "        for key in final.keys():\n",
    "            for g in final[key]:\n",
    "                sign_tuples.append((g,key))\n",
    "\n",
    "        DEGs_runs_all_cell_types_together = {}\n",
    "        for i in range(N):\n",
    "            dfs = []\n",
    "            for ct in cell_types:\n",
    "                df = DEG_details_runs[i]['pos_DEGs_but_not_marker'][ct]\n",
    "                # add column to df with cell type\n",
    "                df['cell_type'] = ct\n",
    "                dfs.append(df)\n",
    "            # concatenate all dataframes in dfs\n",
    "            DEGs_runs_all_cell_types_together[i] = pd.concat(dfs)\n",
    "        all_together = []\n",
    "        for i in range(N):\n",
    "            all_together.append(DEGs_runs_all_cell_types_together[i])\n",
    "        df_all_together = pd.concat(all_together)\n",
    "        df_all_together_sign = df_all_together.merge(pd.DataFrame(sign_tuples, columns=['gene','cell_type']))  \n",
    "        genes_all = df_all_together['gene'].unique()\n",
    "        genes_all_sign = df_all_together_sign['gene'].unique()\n",
    "\n",
    "        logpadj_min_plot = df_all_together['pvals_adj'].min()/10\n",
    "        logpadj_max_plot = 0.5\n",
    "        logf2_max_plot = df_all_together['logf2'].max() + 0.2\n",
    "        logf2_min_plot = -0.2\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in DEGs_runs_all_cell_types_together:\n",
    "            ax.scatter(DEGs_runs_all_cell_types_together[run]['pvals_adj'].to_list(),DEGs_runs_all_cell_types_together[run]['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend(ncols=2)\n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for run in range(N):\n",
    "            df = DEGs_runs_all_cell_types_together[run].merge(pd.DataFrame(sign_tuples, columns=['gene','cell_type']))        \n",
    "            ax.scatter(df['pvals_adj'].to_list(),df['logf2'].to_list(), label='run '+str(run),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend(ncols=2)\n",
    "        #ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        #ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for ct in cell_types:\n",
    "            # select only the rows of the cell type\n",
    "            df = df_all_together[df_all_together['cell_type'] == ct]\n",
    "            ax.scatter(df['pvals_adj'].to_list(),df['logf2'].to_list(), label=str(ct),c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend(ncols=2)\n",
    "        ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_found_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0 \n",
    "        for ct in cell_types:\n",
    "            # select only the rows of the cell type\n",
    "            df = df_all_together_sign[df_all_together_sign['cell_type'] == ct]\n",
    "            ax.scatter(df['pvals_adj'].to_list(),df['logf2'].to_list(), label=ct, c = colors[c])\n",
    "            c = (c + 1)%40\n",
    "        ax.legend(ncols=2)\n",
    "        #ax.set_ylim(logf2_min_plot,logf2_max_plot)\n",
    "        #ax.set_xlim(logpadj_min_plot,logpadj_max_plot)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('pvals_adj')\n",
    "        ax.set_ylabel('logf2')\n",
    "        ax.set_title('DEGs_kept_strategy_2')\n",
    "        plt.show()\n",
    "\n",
    "        genes_all_sets = []\n",
    "        for i in range(0,len(genes_all),20):\n",
    "            genes_all_sets.append(genes_all[i:i+20])\n",
    "        for genes in genes_all_sets:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for gene in genes:\n",
    "                # select only the rows of the cell type\n",
    "                df = df_all_together[df_all_together['gene'] == gene]\n",
    "                # get unique cell_types in df\n",
    "                cell_types = df['cell_type'].unique()\n",
    "                for ct in cell_types:\n",
    "                    df_ct = df[df['cell_type'] == ct]\n",
    "                    ax.scatter(df_ct['pvals_adj'].to_list(),df_ct['logf2'].to_list(), label=gene + ' ('+ct+')',c=colors[c])\n",
    "                    c = (c + 1)%40\n",
    "            # Shrink current axis by 20%\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            # Put a legend to the right of the current axis\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_found_strategy_2')\n",
    "            plt.show()\n",
    "\n",
    "        g2 = open(output_dir+'/DEGs_kept_strategy_2_all_info.txt', 'w+')\n",
    "        genes_all_sets = []\n",
    "        for i in range(0,len(genes_all_sign),20):\n",
    "            genes_all_sets.append(genes_all_sign[i:i+20])\n",
    "        for genes in genes_all_sets:\n",
    "            c = 0\n",
    "            fig, ax = plt.subplots()\n",
    "            for gene in genes:\n",
    "                # select only the rows of the cell type\n",
    "                df = df_all_together_sign[df_all_together_sign['gene'] == gene]\n",
    "                # get unique cell_types in df\n",
    "                cell_types = df['cell_type'].unique()\n",
    "                for ct in cell_types:\n",
    "                    df_ct = df[df['cell_type'] == ct]\n",
    "                    ax.scatter(df_ct['pvals_adj'].to_list(),df_ct['logf2'].to_list(), label=gene + ' ('+ct+')',c=colors[c])\n",
    "                    c = (c + 1)%40\n",
    "                    g2.write(''+gene + ' ' + ct + ' ' + str(df_ct['logf2'].to_list()) + ' ' + str(df_ct['pvals_adj'].to_list()) + '\\n')\n",
    "\n",
    "            # Shrink current axis by 20%\n",
    "            box = ax.get_position()\n",
    "            ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "            # Put a legend to the right of the current axis\n",
    "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncols=2)  \n",
    "            ax.set_xscale('log')\n",
    "            ax.set_xlabel('pvals_adj')\n",
    "            ax.set_ylabel('logf2')\n",
    "            ax.set_title('DEGs_kept_strategy_2')\n",
    "            plt.show()\n",
    "        g2.close() \n",
    "\n",
    "        genes_add = []\n",
    "        for keys in final.keys():\n",
    "            for g in final[keys]:\n",
    "                if g not in genes_add:\n",
    "                    genes_add.append(g)\n",
    "\n",
    "        sc.pl.heatmap(adata,var_names=genes_add,groupby=annotation,standard_scale='var',show_gene_labels=True,save='_strategy_2_genes.png')\n",
    "        adata_sub = adata[~(adata.obs[annotation]=='Hepa'),:]\n",
    "        sc.pl.heatmap(adata_sub,var_names=genes_add,groupby=annotation,standard_scale='var',show_gene_labels=True,save='_strategy_2_genes_noHepa.png')\n",
    "\n",
    "    return final, results_runs, DEG_details_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusteringVSleiden(adata, celltype_column, leiden_column, cell_types = 'all', print_results=True):\n",
    "      \n",
    "    if cell_types == 'all':\n",
    "        cell_types = adata.obs[celltype_column].unique().tolist()  \n",
    "\n",
    "    stacked = (\n",
    "            adata.obs.groupby([leiden_column, celltype_column], as_index=False)\n",
    "            .size()\n",
    "            .pivot(leiden_column, celltype_column)\n",
    "            .fillna(0)\n",
    "        )\n",
    "    stacked_norm = stacked.div(stacked.sum(axis=1), axis=0)\n",
    "    stacked_norm.columns = [x[1] for x in stacked_norm.columns]\n",
    "    stacked_norm.index = [(x,adata.obs[leiden_column].value_counts()[x]) for x in stacked_norm.index]\n",
    "\n",
    "    # get max of each row\n",
    "    max = stacked_norm.max(axis=1)\n",
    "    # get column with max value of each row\n",
    "    max_col = stacked_norm.idxmax(axis=1)\n",
    "\n",
    "    dict_leiden_clusters_per_ct = {}\n",
    "    for i in range(len(stacked_norm)):\n",
    "        if max[i]>0.5:\n",
    "            if max_col[i] not in dict_leiden_clusters_per_ct.keys():\n",
    "                dict_leiden_clusters_per_ct[max_col[i]] = []\n",
    "                if 'Unknown' in stacked_norm.columns:\n",
    "                    dict_leiden_clusters_per_ct[max_col[i]].append((i,np.round(max[i],2),stacked_norm.index[i][1],max_col[i],np.round(stacked_norm['Unknown'][i],2)))\n",
    "                else:\n",
    "                    dict_leiden_clusters_per_ct[max_col[i]].append((i,np.round(max[i],2),stacked_norm.index[i][1],max_col[i],0))\n",
    "        else:\n",
    "            if 'Unknown' not in dict_leiden_clusters_per_ct.keys():\n",
    "                dict_leiden_clusters_per_ct['Unknown'] = []\n",
    "            if 'Unknown' in stacked_norm.columns:\n",
    "                dict_leiden_clusters_per_ct['Unknown'].append((i,np.round(max[i],2),stacked_norm.index[i][1],max_col[i],np.round(stacked_norm['Unknown'][i],2)))\n",
    "            else:\n",
    "                dict_leiden_clusters_per_ct['Unknown'].append((i,np.round(max[i],2),stacked_norm.index[i][1],max_col[i],0))\n",
    "    \n",
    "    leiden_clusters_per_cell_type = []\n",
    "\n",
    "    if 'Unknown' not in cell_types:\n",
    "        cell_types.append('Unknown')\n",
    "\n",
    "    for ct in cell_types:\n",
    "        if ct not in dict_leiden_clusters_per_ct.keys():\n",
    "            leiden_clusters_per_cell_type.append([])\n",
    "        else:\n",
    "            leiden_clusters_per_cell_type.append(dict_leiden_clusters_per_ct[ct])\n",
    "\n",
    "    if print_results:\n",
    "        for i in range(len(cell_types)):\n",
    "            print(cell_types[i])\n",
    "            print(leiden_clusters_per_cell_type[i])\n",
    "        \n",
    "       \n",
    "        for i in range(0,len(stacked_norm),35):\n",
    "            st_n = stacked_norm.iloc[i:i+35,:]\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "            st_n.plot(kind=\"bar\", stacked=True, ax=fig.gca(),colormap=\"tab20b\")\n",
    "            ax.spines[\"top\"].set_visible(False)\n",
    "            ax.spines[\"right\"].set_visible(False)\n",
    "            ax.spines[\"bottom\"].set_visible(False)\n",
    "            ax.spines[\"left\"].set_visible(False)\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "            plt.xlabel(\"Clusters\")\n",
    "            plt.legend(loc=\"center left\", bbox_to_anchor=(1.0, 0.5), fontsize=\"large\")\n",
    "            plt.show()\n",
    "            plt.close(fig)\n",
    "\n",
    "        all_values = []\n",
    "        miniLeiden = leiden_clusters_per_cell_type\n",
    "        for i in range(len(miniLeiden)):\n",
    "            for j in range(len(miniLeiden[i])):\n",
    "                all_values.append(miniLeiden[i][j])\n",
    "        keys = list(set([x[3] for x in all_values]))\n",
    "        dict_plot = {}\n",
    "        for k in keys:\n",
    "            dict_plot[k] = []\n",
    "            for i in range(len(all_values)):\n",
    "                if all_values[i][3] == k:\n",
    "                    dict_plot[k].append(all_values[i][1])\n",
    "\n",
    "        colors = []\n",
    "        for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "\n",
    "        data = []\n",
    "        for k in keys:\n",
    "            data.append(dict_plot[k])\n",
    "\n",
    "        plt.hist(data, color=colors[:len(dict_plot.keys())], label=list(dict_plot.keys()),bins=30,stacked=True)\n",
    "        plt.xlabel('Homogeneity')\n",
    "        plt.ylabel('Cluster Count')\n",
    "        plt.legend(title='Majority cell type')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        homogeneities = [x[1] for x in all_values]\n",
    "        fraction_unknown = [x[4] for x in all_values]\n",
    "        # color point above 0\n",
    "        for i in range(len(homogeneities)):\n",
    "            if fraction_unknown[i] > 0:\n",
    "                plt.scatter(homogeneities[i], fraction_unknown[i], color='black')\n",
    "            else:\n",
    "                plt.scatter(homogeneities[i], fraction_unknown[i], color='blue')\n",
    "        plt.xlabel('Cluster homogeneity')\n",
    "        plt.ylabel('Fraction cell type Unknown')\n",
    "\n",
    "    return leiden_clusters_per_cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_annotations_composition(anndata,sample_name,annotations,names_anno_plot,drop_cell_types=[],plot=True,save=False,saved_as=''):\n",
    "    cell_types = []\n",
    "    for anno in annotations:\n",
    "        cell_types.extend(anndata.obs[anno].unique().to_list())\n",
    "    cell_types = np.unique(cell_types).tolist()\n",
    "    for g in drop_cell_types:\n",
    "        cell_types.remove(g)\n",
    "\n",
    "    all_fractions_per_cell_type = []\n",
    "    for ct in cell_types:\n",
    "        fraction_in_each_annotation = []\n",
    "        for annotation in annotations:\n",
    "            nr_cells = len(anndata.obs[annotation])\n",
    "            ct_counts = anndata.obs[annotation].value_counts()\n",
    "            if ct in ct_counts.index:\n",
    "                count = ct_counts[ct]\n",
    "            else:\n",
    "                count = 0\n",
    "            fraction_in_each_annotation.append((count/nr_cells)*100)\n",
    "        all_fractions_per_cell_type.append(fraction_in_each_annotation)\n",
    "\n",
    "    if plot:\n",
    "        colors = []\n",
    "        for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "        for c in plt.cm.tab20b.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 0\n",
    "        for i in range(len(all_fractions_per_cell_type)):    \n",
    "            ax.scatter(all_fractions_per_cell_type[i],names_anno_plot,label=cell_types[i], c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        plt.xlabel(\"Percentage\")\n",
    "        plt.title(\"Cell type percentages in each annotation of \"+sample_name)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  \n",
    "        # save plot\n",
    "        if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "\n",
    "    return all_fractions_per_cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_annotations_samples_cell_type_percentage(anndata_objects,sample_names,annotations,names_anno_plot,chosen_ct,plot=True,save=False,saved_as='',mean=False,suffix=''):\n",
    "    all_fractions_per_sample = []\n",
    "    for annd in anndata_objects:\n",
    "        fraction_in_each_annotation = []\n",
    "        for annotation in annotations:\n",
    "            nr_cells = len(annd.obs[annotation])\n",
    "            ct_counts = annd.obs[annotation].value_counts()\n",
    "            if chosen_ct in ct_counts.index:\n",
    "                count = ct_counts[chosen_ct]\n",
    "            else:\n",
    "                count = 0\n",
    "            fraction_in_each_annotation.append((count/nr_cells)*100)\n",
    "        all_fractions_per_sample.append(fraction_in_each_annotation)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        if mean:\n",
    "            for i in range(len(all_fractions_per_sample)):    \n",
    "                ax.scatter(all_fractions_per_sample[i],names_anno_plot,label = sample_names[i])\n",
    "            m = np.mean(all_fractions_per_sample,axis=0)\n",
    "            ax.scatter(m.tolist(),names_anno_plot,c='black',label='Mean',marker='x')\n",
    "        else:\n",
    "            for i in range(len(all_fractions_per_sample)):    \n",
    "                ax.scatter(all_fractions_per_sample[i],names_anno_plot,label = sample_names[i])\n",
    "        plt.title(\"Percentage of '\" + chosen_ct + \"' in each annotation\"+suffix)\n",
    "        plt.xlabel(\"Percentage\")  \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))        \n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) \n",
    "        if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "\n",
    "    return all_fractions_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_annotations_samples_mean_composition(anndata_objects,annotations,names_anno_plot,drop_cell_types=[],plot=True,save=False,saved_as='',suffix=''):\n",
    "    cell_types = []\n",
    "    for anno in annotations:\n",
    "        cell_types.extend(anndata_objects[0].obs[anno].unique().to_list())\n",
    "    cell_types = np.unique(cell_types).tolist()\n",
    "    for g in drop_cell_types:\n",
    "        cell_types.remove(g)\n",
    "    sample_compositions = []\n",
    "    for anndata in anndata_objects:\n",
    "        sample_compositions.append(compare_annotations_composition(anndata,'',annotations,names_anno_plot,drop_cell_types,plot=False,save=False,saved_as=''))\n",
    "    mean_composition = np.mean(sample_compositions,axis=0)\n",
    "    colors = []\n",
    "    for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "    for c in plt.cm.tab20b.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        c = 20\n",
    "        for i in range(len(mean_composition)):   \n",
    "            # get sum of all previous values in mean_composition\n",
    "            b = 0\n",
    "            for j in range(i):\n",
    "                b += mean_composition[j] \n",
    "            ax.barh(names_anno_plot,mean_composition[i],label=cell_types[i], color=colors[c],left=b)\n",
    "            c = (c + 2)%40\n",
    "        plt.title(\"Composition (no 'Hepa') of each annotation averaged over the samples\"+suffix)\n",
    "        plt.xlabel(\"Percentage\") \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))        \n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) \n",
    "        # rotate figure\n",
    "        #plt.xticks(rotation=90)\n",
    "        if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "    return mean_composition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_annotations_cluster_homogeneity(anndata,sample_name,annotations,names_anno_plot,drop_cell_types=[],plot=True,save=False,saved_as=''):\n",
    "    cell_types = []\n",
    "    for anno in annotations:\n",
    "        cell_types.extend(anndata.obs[anno].unique().to_list())\n",
    "    cell_types = np.unique(cell_types).tolist()\n",
    "    if 'Unknown' not in cell_types:\n",
    "        cell_types.append('Unknown')\n",
    "    for g in drop_cell_types:\n",
    "        cell_types.remove(g)\n",
    "    \n",
    "    all_homog_per_ct = []\n",
    "    for ct in cell_types:\n",
    "        homog_in_each_annotation = []\n",
    "        for annotation in annotations:\n",
    "            leiden_clusters_per_ct = clusteringVSleiden(anndata,annotation,'leiden',cell_types=[ct],print_results=False)\n",
    "            all_max = []\n",
    "            for cluster in leiden_clusters_per_ct[0]:\n",
    "                all_max.append(cluster[1])\n",
    "            mean_all_max = np.mean(all_max)\n",
    "            homog_in_each_annotation.append(mean_all_max)\n",
    "        all_homog_per_ct.append(homog_in_each_annotation)\n",
    "\n",
    "    if plot:\n",
    "        colors = []\n",
    "        for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "        for c in plt.cm.tab20b.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "        c = 0\n",
    "        fig, ax = plt.subplots()\n",
    "        for i in range(len(cell_types)):    \n",
    "            ax.scatter(all_homog_per_ct[i],names_anno_plot,label = cell_types[i],c=colors[c])\n",
    "            c = (c + 1)%40\n",
    "        plt.xlabel(\"Average homogeneity of leiden clusters\")\n",
    "        plt.title(\"Cluster homogeneity in each annotation of \"+sample_name)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "        if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "        \n",
    "    return cell_types, all_homog_per_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_annotations_samples_cluster_homogeneity(anndata_objects,sample_names,annotations,names_anno_plot,drop_cell_types=[],plot=True,save=False,saved_as='',suffix='',mean=False):\n",
    "    cell_types = []\n",
    "    for anndata in anndata_objects:\n",
    "        for anno in annotations:\n",
    "            cell_types.extend(anndata.obs[anno].unique().to_list())\n",
    "    cell_types = np.unique(cell_types).tolist()\n",
    "    for g in drop_cell_types:\n",
    "        cell_types.remove(g)\n",
    "\n",
    "    all_homog_per_sample = []\n",
    "    for annd in anndata_objects:\n",
    "        homog_in_each_annotation = []\n",
    "        for annotation in annotations:\n",
    "            leiden_clusters_per_ct = clusteringVSleiden(annd,annotation,'leiden',cell_types=cell_types,print_results=False)\n",
    "            all_max = []\n",
    "            for i in range(len(leiden_clusters_per_ct)):\n",
    "                for cluster in leiden_clusters_per_ct[i]:\n",
    "                    all_max.append(cluster[1])\n",
    "            mean_all_max = np.mean(all_max)\n",
    "            homog_in_each_annotation.append(mean_all_max)\n",
    "        all_homog_per_sample.append(homog_in_each_annotation)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        if mean:\n",
    "            for i in range(len(all_homog_per_sample)):    \n",
    "                ax.scatter(all_homog_per_sample[i],names_anno_plot,label = sample_names[i])\n",
    "            m = np.mean(all_homog_per_sample,axis=0)\n",
    "            ax.scatter(m.tolist(),names_anno_plot,c='black',label='Mean',marker='x')\n",
    "        else:\n",
    "            for i in range(len(all_homog_per_sample)):    \n",
    "                ax.scatter(all_homog_per_sample[i],names_anno_plot,label = sample_names[i])\n",
    "        plt.title(\"Cluster homogeneity of each annotation\" + suffix)\n",
    "        plt.xlabel(\"Average homogeneity of leiden clusters\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5)) \n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        \n",
    "        if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "\n",
    "    return all_homog_per_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_cells_unknown_leiden_cluster(anndata,annotation_column,leiden_column):\n",
    "    leiden_clusters_per_ct = clusteringVSleiden(anndata,annotation_column,leiden_column,cell_types=['Unknown'],print_results=False)\n",
    "    cells_in_unknown_cluster = 0\n",
    "    for cluster in leiden_clusters_per_ct[0]:\n",
    "        cells_in_unknown_cluster += cluster[2]\n",
    "    return (cells_in_unknown_cluster/len(anndata.obs[annotation_column]))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_annotations_samples_cluster_homogeneity_percentage_unknown(anndata_objects,sample_names,annotations,names_anno_plot,plot=True,save=False,saved_as='',mean=False,suffix=''):\n",
    "    all_perc_per_sample = []\n",
    "    for annd in anndata_objects:\n",
    "        perc_in_each_annotation = []\n",
    "        for annotation in annotations:\n",
    "            perc_in_each_annotation.append(100.0-percentage_cells_unknown_leiden_cluster(annd,annotation,'leiden'))\n",
    "        all_perc_per_sample.append(perc_in_each_annotation)\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        if mean:\n",
    "            for i in range(len(all_perc_per_sample)):    \n",
    "                ax.scatter(all_perc_per_sample[i],names_anno_plot,label = sample_names[i])\n",
    "            m = np.mean(all_perc_per_sample,axis=0)\n",
    "            ax.scatter(m.tolist(),names_anno_plot,c='black',label='Mean',marker='x')\n",
    "        else:\n",
    "            for i in range(len(all_perc_per_sample)):    \n",
    "                ax.scatter(all_perc_per_sample[i],names_anno_plot,label = sample_names[i])\n",
    "        plt.title(\"Percentage of cells in Leiden cluster with known cell type\"+suffix)\n",
    "        plt.xlabel(\"Percentage of cells\")   \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))       \n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])        \n",
    "        if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "\n",
    "    return all_perc_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_annotations(anndata,annotations,names_anno_plot,plot=True,save=False,saved_as='',suffix=''):\n",
    "    array = np.empty((len(annotations), len(annotations)))\n",
    "    for i in range(len(annotations)):\n",
    "        for j in range(len(annotations)):\n",
    "            c1 = anndata.obs[annotations[i]]\n",
    "            c2 = anndata.obs[annotations[j]]\n",
    "            c1 = c1.tolist()\n",
    "            c2 = c2.tolist()\n",
    "            count = 0\n",
    "            for k in range(len(c1)):\n",
    "                if c1[k] == c2[k]:\n",
    "                    count += 1\n",
    "            array[i][j] = count/len(c1)\n",
    "    if plot:\n",
    "        svm = sns.heatmap(array, annot=True, annot_kws={'size': 8})\n",
    "        plt.xticks(np.arange(len(annotations))+0.5, names_anno_plot, rotation=90)\n",
    "        plt.yticks(np.arange(len(annotations))+0.5, names_anno_plot, rotation=0)\n",
    "        plt.tick_params(axis='both', which='both', length=0)\n",
    "        plt.title(\"Similarity matrix\"+suffix)\n",
    "        figure = svm.get_figure()\n",
    "        if save:\n",
    "            figure.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix_annotations_avg_samples(anndata_objects,annotations,names_anno_plot,save=False,saved_as='',suffix=''):\n",
    "    arrays = []\n",
    "    for anndata in anndata_objects:\n",
    "        a = similarity_matrix_annotations(anndata,annotations,names_anno_plot,plot=False)\n",
    "        arrays.append(a)\n",
    "    avg_array = np.mean(arrays,axis=0)\n",
    "    svm = sns.heatmap(avg_array, annot=True, annot_kws={'size': 8})\n",
    "    plt.xticks(np.arange(len(annotations))+0.5, names_anno_plot, rotation=90)\n",
    "    plt.yticks(np.arange(len(annotations))+0.5, names_anno_plot, rotation=0)\n",
    "    plt.tick_params(axis='both', which='both', length=0)\n",
    "    plt.title(\"Similarity matrix averaged over the samples\"+suffix)\n",
    "    figure = svm.get_figure()\n",
    "    if save:\n",
    "        figure.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')\n",
    "    return avg_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence(anndata,annotation,plot=True):\n",
    "    sq.gr.spatial_neighbors(anndata, coord_type=\"generic\")\n",
    "    sq.gr.nhood_enrichment(anndata, cluster_key=annotation)\n",
    "    anndata.uns[annotation + '_nhood_enrichment']['zscore'] = np.nan_to_num(anndata.uns[annotation + '_nhood_enrichment']['zscore'], nan=0)\n",
    "    if plot:\n",
    "        sq.pl.nhood_enrichment(anndata, cluster_key=annotation,mode='zscore',method='ward',optimal_ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_co_occurrence(anndata,annotation1,annotation2,plot=True):\n",
    "    co_occurrence(anndata,annotation1,plot=False)\n",
    "    co_occurrence(anndata,annotation2,plot=False)\n",
    "    array_1 = anndata.uns[annotation1 + '_nhood_enrichment']['zscore']\n",
    "    array_2 = anndata.uns[annotation2 + '_nhood_enrichment']['zscore']\n",
    "    cell_types_1 = np.unique(anndata.obs[annotation1]).tolist()\n",
    "    cell_types_2 = np.unique(anndata.obs[annotation2]).tolist()\n",
    "    df_1_original = pd.DataFrame(array_1, columns=cell_types_1, index=cell_types_1)\n",
    "    df_2_original = pd.DataFrame(array_2, columns=cell_types_2, index=cell_types_2)\n",
    "    df_1 = df_1_original.copy(deep=True)\n",
    "    df_2 = df_2_original.copy(deep=True)\n",
    "    cell_types_not_in_both = list(set(cell_types_1) ^ set(cell_types_2))\n",
    "    print(cell_types_not_in_both)\n",
    "    for cellt in cell_types_not_in_both:\n",
    "        if cellt in cell_types_1:\n",
    "            # drop column and row with this cell\n",
    "            df_1 = df_1.drop(cellt, axis=1)\n",
    "            df_1 = df_1.drop(cellt, axis=0)\n",
    "        else:\n",
    "            df_2 = df_2.drop(cellt, axis=1)\n",
    "            df_2 = df_2.drop(cellt, axis=0)\n",
    "    if 'Chol' in df_1.columns and 'Portal vein' in df_1.columns and 'Oth im' in df_1.columns:\n",
    "        df_1 = df_1.reindex(['Chol','Portal vein','Oth im'] + [ct for ct in df_1.columns if ct not in ['Chol','Portal vein','Oth im']],axis=1)\n",
    "        df_1 = df_1.reindex(['Chol','Portal vein','Oth im'] + [ct for ct in df_1.columns if ct not in ['Chol','Portal vein','Oth im']],axis=0)\n",
    "    if 'Chol' in df_1_original.columns and 'Portal vein' in df_1_original.columns and 'Oth im' in df_1_original.columns:\n",
    "        df_1_original = df_1_original.reindex(['Chol','Portal vein','Oth im'] + [ct for ct in df_1_original.columns if ct not in ['Chol','Portal vein','Oth im']],axis=1)\n",
    "        df_1_original = df_1_original.reindex(['Chol','Portal vein','Oth im'] + [ct for ct in df_1_original.columns if ct not in ['Chol','Portal vein','Oth im']],axis=0)\n",
    "    if 'Chol' in df_2_original.columns and 'Portal vein' in df_2_original.columns and 'Oth im' in df_2_original.columns:\n",
    "        df_2_original = df_2_original.reindex(['Chol','Portal vein','Oth im'] + [ct for ct in df_2_original.columns if ct not in ['Chol','Portal vein','Oth im']],axis=1)\n",
    "        df_2_original = df_2_original.reindex(['Chol','Portal vein','Oth im'] + [ct for ct in df_2_original.columns if ct not in ['Chol','Portal vein','Oth im']],axis=0)    \n",
    "    if 'Kupf' in df_1.columns and 'Stel' in df_1.columns and 'LSEC' in df_1.columns:\n",
    "        df_1 = df_1.reindex(['Kupf','Stel','LSEC'] + [ct for ct in df_1.columns if ct not in ['Kupf','Stel','LSEC']],axis=1)\n",
    "        df_1 = df_1.reindex(['Kupf','Stel','LSEC'] + [ct for ct in df_1.columns if ct not in ['Kupf','Stel','LSEC']],axis=0)\n",
    "    if 'Kupf' in df_1_original.columns and 'Stel' in df_1_original.columns and 'LSEC' in df_1_original.columns:\n",
    "        df_1_original = df_1_original.reindex(['Kupf','Stel','LSEC'] + [ct for ct in df_1_original.columns if ct not in ['Kupf','Stel','LSEC']],axis=1)\n",
    "        df_1_original = df_1_original.reindex(['Kupf','Stel','LSEC'] + [ct for ct in df_1_original.columns if ct not in ['Kupf','Stel','LSEC']],axis=0)\n",
    "    if 'Kupf' in df_2_original.columns and 'Stel' in df_2_original.columns and 'LSEC' in df_2_original.columns:\n",
    "        df_2_original = df_2_original.reindex(['Kupf','Stel','LSEC'] + [ct for ct in df_2_original.columns if ct not in ['Kupf','Stel','LSEC']],axis=1)\n",
    "        df_2_original = df_2_original.reindex(['Kupf','Stel','LSEC'] + [ct for ct in df_2_original.columns if ct not in ['Kupf','Stel','LSEC']],axis=0)\n",
    "    df_2 = df_2.reindex(columns=df_1.columns, index=df_1.index)\n",
    "    df_diff = df_1 - df_2\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(df_1_original, cmap='coolwarm', center=0, annot=True, fmt=\".1f\",cbar_kws={'label': 'nhood_enrichm z_score'})\n",
    "        plt.title(annotation1)\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(df_2_original, cmap='coolwarm', center=0, annot=True, fmt=\".1f\",cbar_kws={'label': 'nhood_enrichm z_score'})\n",
    "        plt.title(annotation2)\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(df_diff, cmap='coolwarm', center=0, annot=True, fmt=\".1f\",cbar_kws={'label': 'nhood_enrichm z_score'})\n",
    "        plt.title(annotation1 + ' - ' + annotation2)\n",
    "    return df_1_original, df_2_original, df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_df(dfs,title):\n",
    "    cell_types = dfs[0].index\n",
    "    for i in range(1,len(dfs)):\n",
    "        cell_types = cell_types.intersection(dfs[i].index)\n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = dfs[i].loc[cell_types]\n",
    "        dfs[i] = dfs[i][cell_types]\n",
    "    dfs_mean = sum(dfs)/len(dfs)\n",
    "    dfs_mean = dfs_mean.round(1)\n",
    "    sns.heatmap(dfs_mean, cmap='coolwarm', center=0, annot=True, fmt=\".1f\",cbar_kws={'label': 'nhood_enrichm z_score'})\n",
    "    plt.title(title)\n",
    "    return dfs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changing_cell_types(anndata,annotation1,annotation2,cut_off=0.05):\n",
    "    l1 = anndata.obs[annotation1]\n",
    "    l2 = anndata.obs[annotation2]\n",
    "    # compare l1 to l2 value by value\n",
    "    diff = []\n",
    "    for i in range(len(l1)):\n",
    "        if l1[i] != l2[i]:\n",
    "            diff.append(False)\n",
    "        else:\n",
    "            diff.append(True)          \n",
    "    l1_diff = [l1[i] for i in range(len(diff)) if diff[i] == False]\n",
    "    l2_diff = [l2[i] for i in range(len(diff)) if diff[i] == False]\n",
    "    false_count = [1 if x == False else 0 for x in diff]\n",
    "    #print('Percentage changed: ')\n",
    "    #print(round(100*sum(false_count )/len(l1),2))\n",
    "    changes = {}\n",
    "    changes_output = []\n",
    "    for i in range(len(l1_diff)):\n",
    "        if l1_diff[i] not in changes.keys():\n",
    "            changes[l1_diff[i]] = [l2_diff[i]]\n",
    "        else:\n",
    "            changes[l1_diff[i]].append(l2_diff[i])\n",
    "    for key in changes.keys():\n",
    "        cts = np.unique(changes[key],return_counts=True)\n",
    "        a = cts[0].tolist()\n",
    "        b = cts[1].tolist()\n",
    "        for i in range(len(a)):\n",
    "            changes_output.append([(key,a[i]),round(100*b[i]/len(l1),2)])\n",
    "    changes_output = sorted(changes_output, key=lambda x: x[1], reverse=True)\n",
    "    changes_output = [x for x in changes_output if x[1] >= cut_off]\n",
    "    return changes_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differences_composition_annotation_methods(anndata_objects,original_annotations,new_annotations,original_name,new_name,marker_names,cut_off=0.5,save=False,saved_as='',suffix=''):\n",
    "    changes = {}\n",
    "    for i in range(len(marker_names)):\n",
    "        changes[marker_names[i]] = []\n",
    "        for anndata in anndata_objects:\n",
    "            changes[marker_names[i]].append(changing_cell_types(anndata,original_annotations[i],new_annotations[i]))\n",
    "    changes_slices_together = {}\n",
    "    changes_kept_cut_off = []\n",
    "    for markers in marker_names:\n",
    "        changes_slices_together[markers] = {}\n",
    "        for i in range(len(anndata_objects)):\n",
    "            for j in range(len(changes[markers][i])):\n",
    "                if changes[markers][i][j][0] in changes_slices_together[markers].keys():\n",
    "                    changes_slices_together[markers][changes[markers][i][j][0]] += changes[markers][i][j][1]\n",
    "                else:\n",
    "                    changes_slices_together[markers][changes[markers][i][j][0]] = changes[markers][i][j][1]\n",
    "        for key in changes_slices_together[markers].keys():\n",
    "            changes_slices_together[markers][key] = changes_slices_together[markers][key]/len(anndata_objects)  \n",
    "            if changes_slices_together[markers][key] >= cut_off:\n",
    "                changes_kept_cut_off.append(key) \n",
    "    changes_kept_cut_off = list(set(changes_kept_cut_off))\n",
    "    for markers in marker_names:\n",
    "        filtered_keys = [key for key in changes_slices_together[markers].keys() if key in changes_kept_cut_off]\n",
    "        changes_slices_together[markers] = {key: changes_slices_together[markers][key] for key in filtered_keys}\n",
    "    values_of_changes_kept = []\n",
    "    for ch in changes_kept_cut_off:\n",
    "        values = []\n",
    "        for markers in marker_names:\n",
    "            if ch in changes_slices_together[markers].keys():\n",
    "                values.append(changes_slices_together[markers][ch])\n",
    "            else:\n",
    "                values.append(0)\n",
    "        values_of_changes_kept.append(values)\n",
    "    values_of_changes_kept\n",
    "    mean_values = np.mean(values_of_changes_kept,axis=1)\n",
    "    order = np.argsort(mean_values)\n",
    "    order = order[::-1]\n",
    "    values_of_changes_kept = np.array(values_of_changes_kept)[order].tolist()\n",
    "    changes_kept_cut_off = np.array(changes_kept_cut_off)[order].tolist()\n",
    "    colors = []\n",
    "    for c in plt.cm.tab20.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "    for c in plt.cm.tab20b.colors: colors.append(matplotlib.colors.to_hex(c))\n",
    "    fig, ax = plt.subplots()\n",
    "    c = 20\n",
    "    b = [0]*len(marker_names)\n",
    "    for i in range(len(changes_kept_cut_off)):    \n",
    "        ax.barh(marker_names,values_of_changes_kept[i],label=str(changes_kept_cut_off[i][0])+' -> '+str(changes_kept_cut_off[i][1]), color=colors[c],left=b)\n",
    "        b = [values_of_changes_kept[i][x]+b[x] for x in range(len(values_of_changes_kept[0]))]\n",
    "        c = (c + 2)%40\n",
    "    plt.title(\"Differences in annotation (\"+original_name+' -> '+new_name+\") averaged over slices\"+suffix)\n",
    "    plt.xlabel(\"Percentage\") \n",
    "    ax.legend()\n",
    "    # add title to legend\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.45),title='Cut-off = '+str(cut_off)+'%')        \n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height]) \n",
    "    if save:\n",
    "            plt.savefig(saved_as+'.png',dpi=300,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
